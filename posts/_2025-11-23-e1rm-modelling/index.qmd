---
title: "Title"
description: |
  Subtitle here
author: Mitch Henderson
date: 2025-11-23
thumbnailImage: /img/nrl_finals_probs.png
draft: true
format:
  html:
    code-fold: true
    code-tools: true
    html-table-processing: none
knitr:
    opts_chunk:
      dev: "ragg_png"
---

## *tl;dr*: enter takeaway here

<br>

[S&C coaches](https://en.wikipedia.org/wiki/Strength_and_conditioning_coach) collect training data to monitor progress and evaluate the effectiveness of their programming. A common method in strength training is to calculate an [**estimated one repetition maximum** (e1RM)](https://en.wikipedia.org/wiki/One-repetition_maximum#Estimating_1RM) using a formula and track it's changes over time. Lots of coaches are happy to use e1RM as a progress indicator instead of true 1RM testing within a program or in-season because it doesn't impact training (integrates into existing training sessions), is safer (lower weight), and data can be collected more frequently (enabling faster program adjustments). [True 1RM](https://en.wikipedia.org/wiki/One-repetition_maximum#Measuring_1RM) testing might only be programmed a handful of times per season (if at all) so using training data to regularly estimate strength adaptations or detect when a program should be adjusted is a good idea.

```{r}
#| output: false

library(tidyverse)
library(gganimate)
library(scales)
library(ggtext)
library(gt)
library(gtExtras)
library(sn) # skewed normal distribution function

mitchhenderson::font_hoist("Myriad Pro")
socials <- mitchhenderson::social_caption(icon_colour = "dodgerblue")

colours <- c("#E31937", "#134A8E")

# theme_set
```

## The problem

There are a lot of different ways to calculate e1RM.

```{r}
#| warning: false

# Define the 1RM estimation formulas
# Each formula calculates %1RM based on number of reps
formulas <- list(
  Epley = function(reps) {
    # Epley: 1RM = weight × (1 + reps/30)
    # Therefore: %1RM = 100 / (1 + reps/30)
    100 / (1 + reps / 30)
  },

  Brzycki = function(reps) {
    # Brzycki: 1RM = weight × (36/(37 - reps))
    # Therefore: %1RM = 100 × (37 - reps) / 36
    100 * (37 - reps) / 36
  },

  Mayhew = function(reps) {
    # Mayhew: 1RM = (100 × weight) / (52.2 + 41.9 × exp(-0.055 × reps))
    # Therefore: %1RM = 52.2 + 41.9 × exp(-0.055 × reps)
    52.2 + 41.9 * exp(-0.055 * reps)
  },

  Lombardi = function(reps) {
    # Lombardi: 1RM = weight × reps^0.10
    # Therefore: %1RM = 100 / reps^0.10
    100 / (reps^0.10)
  },

  `O'Conner` = function(reps) {
    # O'Conner: 1RM = weight × (1 + reps/40)
    # Therefore: %1RM = 100 / (1 + reps/40)
    100 / (1 + reps / 40)
  },

  Wathan = function(reps) {
    # Wathan: 1RM = (100 × weight) / (48.8 + 53.8 × exp(-0.075 × reps))
    # Therefore: %1RM = 48.8 + 53.8 × exp(-0.075 × reps)
    48.8 + 53.8 * exp(-0.075 * reps)
  },

  Lander = function(reps) {
    # Lander: 1RM = (100 × weight) / (101.3 - 2.67123 × reps)
    # Therefore: %1RM = 101.3 - 2.67123 × reps
    101.3 - 2.67123 * reps
  }
)

# Generate data for reps 1 to 20
reps_range <- 1:20

# Create a tidy dataframe with all formulas
e1rm_data <- tibble(reps = reps_range) |>
  crossing(formula = names(formulas)) |>
  mutate(
    percent_1rm = map2_dbl(formula, reps, ~ formulas[[.x]](.y))
  )

e1rm_data_animated <- e1rm_data |>
  crossing(highlight = unique(e1rm_data$formula)) |>
  mutate(
    is_highlighted = formula == highlight,
    line_color = if_else(is_highlighted, "highlighted", "grey"),
    label = if_else(is_highlighted & reps == max(reps), formula, NA_character_),
    line_size = if_else(is_highlighted, 2, 0.5)
  )

animated_plot <- e1rm_data_animated |>
  ggplot(aes(x = reps, y = percent_1rm, group = formula)) +
  coord_cartesian(xlim = c(1, 20), clip = "off") +
  geom_line(
    data = e1rm_data_animated |> filter(!is_highlighted),
    aes(linewidth = line_size),
    colour = "grey70"
  ) +
  geom_line(
    data = e1rm_data_animated |> filter(is_highlighted),
    aes(linewidth = line_size),
    colour = "#E31937"
  ) +
  geom_text(
    aes(label = label),
    colour = "#E31937",
    family = "Myriad Pro Regular",
    hjust = 0,
    nudge_x = 0.5,
    size = 6,
    fontface = "bold",
    show.legend = FALSE
  ) +
  scale_linewidth_identity() +
  scale_x_continuous(
    breaks = seq(1, 20, 1)
  ) +
  scale_y_continuous(
    labels = label_percent(scale = 1),
    breaks = seq(40, 100, 10),
    limits = c(40, 100)
  ) +
  labs(
    title = "1RM Estimation Formulas",
    x = "Number of Repetitions",
    y = NULL,
    subtitle = "% of 1RM",
    caption = socials
  ) +
  theme_classic(base_size = 16, base_family = "Myriad Pro Regular") +
  theme(
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(size = 14, color = "grey40", face = "bold"),
    axis.title.x = element_text(size = 14, color = "grey40", face = "bold"),
    panel.grid = element_blank(),
    plot.margin = margin(10, 100, 10, 10),
    plot.caption = element_markdown(color = "grey50", size = 10),
    legend.position = "none",
    axis.ticks = element_blank(),
    axis.line = element_line(colour = "grey50"),
    plot.title.position = "plot"
  ) +
  transition_manual(
    highlight,
    cumulative = FALSE
  )

# Render the animation
animate(
  animated_plot,
  nframes = 80,
  fps = 10,
  width = 8,
  height = 4.5,
  device = "ragg_png"
)
```

But none of these e1RM formulas:

-   Account for strength endurance differences between athletes

    Some athletes (fast twitch, higher metabolic cost per rep) have high 1RMs but find higher rep sets challenging. Other athletes (better oxidative capacity, lower metabolic cost per rep) can perform many reps at moderate intensities but quickly hit their 1RM ceiling with more weight. **I want my e1RM estimate to take into account what I know about the physiological characteristics of the athlete**. If a fast twitch athlete does a max reps set of 14 x 100kg, I expect their 1RM to be higher than a more oxidative athlete performing the same 14 x 100kg because I know they are better suited to high intensity work.

    e1RM formulas don't do this.

-   Tell me how certainty they are in their estimate

    The standard formulas WILL ALWAYS give you a 1RM estimate, doesn't matter how UNconfident it is. This estimate will always just be a single value. There's a big difference in how I'd interpret a 100kg e1RM if it's 80% certain of being between 97.5–102.5kg (precise) versus 80% certain of being between 77.5–122.5kg (practically useless). There's also a big difference in the certainty we can expect from these models when the athlete does 2-5 reps (higher certainty) compared 10+ reps (lower certainty). We also become more certain about an athlete's ability the more we work with them. I have a lot more confidence predicting the 1RM of an athlete I've worked with and collected training data on for years compared to someone new with little training data available. **I want my e1RM estimate to incorporate all these sources of uncertainty so I can interpret and act accordingly**.

    e1RM formulas don't do this.

## My solution

The idea is basically to build a statistical model that takes into account which athlete it's estimating the 1RM for. The model will be trained on the athlete's past data so it learns how they handle higher weight vs higher reps and will adjust accordingly. It's kind of like a smarter version of the standard e1RM formulas that change how they work based on the athlete and what it knows about them.

The model will also be what's called a [Bayesian](https://en.wikipedia.org/wiki/Bayesian_statistics) model in the statistics world. These have advantages over [conventional](https://en.wikipedia.org/wiki/Frequentist_probability) statistical models when it comes to expressing uncertainty ([among other things](https://www.youtube.com/watch?v=R6d-AbkhBQ8)). So instead of just getting a number, you get a full distribution of numbers that can either be interpreted as is, or summarised however you want (e.g., 80% are between *this* number and *that* number). This distribution will account for all the sources of upstream uncertainty (amount of data available on the athlete, number of reps they completed, etc).

To show you what I mean, I'll start by simulating some data.

```{r}
set.seed(2534)

# Population hyperparameters (ground truth)
n_athletes <- 30
mean_n_obs_per_athlete <- 15
min_n_obs <- 5
max_n_obs <- 30

# True 1RM population parameters
pop_mean_1rm <- 140
pop_sd_1rm <- 15

# Endurance coefficient population parameters
pop_mean_endurance <- 30
pop_sd_endurance <- 10

# Observation noise
obs_noise_sd <- 2.5

# Skewness for observed weights (negative = left skew)
skew_alpha <- -2

# Generate athlete-level ground truth
athletes <- tibble(
  athlete_id = 1:n_athletes,
  true_1rm = rnorm(n_athletes, mean = pop_mean_1rm, sd = pop_sd_1rm),
  true_endurance = rnorm(
    n_athletes,
    mean = pop_mean_endurance,
    sd = pop_sd_endurance
  ),
  n_observations = sample(min_n_obs:max_n_obs, n_athletes, replace = TRUE)
)

# Generate observations
sim_data <- athletes |>
  rowwise() |>
  reframe(
    athlete_id = athlete_id,
    true_1rm = true_1rm,
    true_endurance = true_endurance,
    session_id = seq_len(n_observations),
    reps = sample(2:15, n_observations, replace = TRUE)
  ) |>
  mutate(
    # Theoretical weight from modified Epley formula
    weight_theoretical = true_1rm / (1 + reps / true_endurance),

    # Left-skewed noise using skew-normal distribution
    weight_observed = weight_theoretical +
      rsn(n(), xi = 0, omega = obs_noise_sd, alpha = skew_alpha)
  )
```

I've defined the "squad" (30 athletes) to have a mean 1RM of 140 and standard deviation of 20 drawn from a random normal distribution. I also assign them an **endurance ability** (also from normal distribution).

Each athlete will have data from somewhere between 5 and 30 previous training sessions where they've done this exercises til failure.

For each of these max rep sets, the athletes complete somewhere between 2 and 15 reps. I calculate a theoretical weight for the set using the simulated 1RM and reps based on a modified version of the Epley formula (arguably most commonly used, modified to account for endurance ability).

Finally, I simulate the actual weight they lifted for the set by taking the weight they theoretically could lift given their simulated 1RM and reps, added some random noise (because humans just work like that) from a negative skew-normal distribution. I chose negative skew-normal instead of regular normal because I think there's a lot more reasons why an athlete can be down from their theoretical 1RM level on any given day (fatigue, injury, soreness, environment, etc) than above it (strength adaptation). This means that on most days, what they've lifted will be a bit less than what the 1RM formula predicts they could.

This simulation gives me `r nrow(sim_data)` max rep sets across the 30 athletes. 10 picked at random look like this:

```{r}
sim_data |>
  slice_sample(n = 10) |>
  mutate(across(where(is.numeric), \(x) round(x, 1))) |>
  gt() |>
  gt_theme_538(quiet = TRUE)
```
