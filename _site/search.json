[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mitch Henderson",
    "section": "",
    "text": "SportüèÖ | Science üë®‚Äçüî¨ | Data üíª\nResume"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Making 1 rep max estimates more accurate and honest\n\n\nUse more of the information you have.\n\n\n\n\n\nJan 2, 2026\n\n\nMitch Henderson\n\n\n\n\n\n\n\n\n\n\n\n\nHow many wins do NRL teams need to make the finals?\n\n\nIt depends, but Monte Carlo simulations give us a pretty good idea\n\n\n\n\n\nJan 27, 2025\n\n\nMitch Henderson\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Catapult‚Äôs running imbalance data\n\n\nThis post shows how running symmetry data can be exported from Catapult Openfield, then imported and visualised in R.\n\n\n\n\n\nFeb 10, 2021\n\n\nMitch Henderson\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising Apple Health data |Guest post by Heidi Thornton\n\n\nTracking data from your Apple watch doesn‚Äôt have to stay in an app. This post shows you how it can be exported, manipulated, and visualised using R.\n\n\n\n\n\nMay 19, 2020\n\n\nHeidi Thornton\n\n\n\n\n\n\n\n\n\n\n\n\nMaking better visualisations using ggplot2 in R\n\n\nGreat visualisations help communicate your message more clearly. This post shows you an example of my process.\n\n\n\n\n\nApr 22, 2020\n\n\nMitch Henderson\n\n\n\n\n\n\n\n\n\n\n\n\nTidying Catapult 10Hz export data\n\n\nThe export format of Catapult‚Äôs 10Hz GPS data isn‚Äôt ideal for analysis. This post shows you how to tidy it using R.\n\n\n\n\n\nApr 5, 2020\n\n\nMitch Henderson\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-04-22-how-a-sports-scientist-can-use-ggplot2-to-make-a-stunning-dataviz.html",
    "href": "posts/2020-04-22-how-a-sports-scientist-can-use-ggplot2-to-make-a-stunning-dataviz.html",
    "title": "Making better visualisations using ggplot2 in R",
    "section": "",
    "text": "‚ÄúThe ability to take data‚Äîto be able to understand it, to process it, to extract value from it, to visualize it, to communicate it‚Äîthat‚Äôs going to be a hugely important skill in the next decades, ‚Ä¶ because now we really do have essentially free and ubiquitous data. So the complimentary scarce factor is the ability to understand that data and extract value from it.‚Äù\n\n‚Äî Hal Varian, The McKinsey Quarterly, Jan 2009\n\n\nGreat results and important messages from sports scientists and S&C coaches are too often lost at the final and most important hurdle of the scientific process: communication.\nA clear, considered, and engaging visualisation helps by presenting the data in a way that‚Äôs digestible to people, not just machines.\nOn the 13th April 2020, I tweeted a thread of visualisations that I‚Äôd made recreating the work of Tom Worville of The Athletic.\n\n\nInspired by the work of @Worville showing @LFC‚Äôs age profile over the past few seasons, I tried to recreate his charts for some other competition-winning üèÜ teams over the last few years using #ggplot in #rstats. A thread.1/6 pic.twitter.com/F9m4oVbLG0\n\n‚Äî Mitch Henderson (@mitchhendo_) April 13, 2020\n\n\nThis post will take you through the process of how I generated this one:\n\nThe full code will be posted at the end, as throughout the post I‚Äôll be going through parts of it bit by bit.\nIf you‚Äôd prefer to watch me do it, this video shows me going through the whole process:\n\n\n\n\n\nStep 1 | Data prep\n\nCollate the data\nThe data that we will use needs to be in this format:\n\n\n\n\n\nplayer_name\npercent_involvement\ndob\narrival_at_team\nreference_date\n\n\n\n\nAndrej Kramaric\n0.0070175\n19/06/1991\n16/01/2015\n15/05/2016\n\n\nAndy King\n0.3105263\n29/10/1988\n1/07/2007\n15/05/2016\n\n\nChristian Fuchs\n0.7926901\n7/04/1986\n1/07/2015\n15/05/2016\n\n\nDaniel Amartey\n0.0304094\n21/12/1994\n22/01/2016\n15/05/2016\n\n\nDanny Drinkwater\n0.8868421\n5/03/1990\n20/01/2012\n15/05/2016\n\n\nDanny Simpson\n0.7631579\n4/01/1987\n30/08/2014\n15/05/2016\n\n\nDemarai Gray\n0.0546784\n28/06/1996\n4/01/2016\n15/05/2016\n\n\nGokhan Inler\n0.0567251\n27/06/1984\n19/08/2015\n15/05/2016\n\n\nJamie Vardy\n0.9160819\n11/01/1987\n1/07/2012\n15/05/2016\n\n\nJeffrey Schlupp\n0.4055556\n23/12/1992\n1/07/2010\n15/05/2016\n\n\nJoe Dodoo\n0.0058480\n29/06/1995\n1/08/2013\n15/05/2016\n\n\nKasper Schmeichel\n1.0000000\n5/11/1986\n1/07/2011\n15/05/2016\n\n\nLeonardo Ulloa\n0.2877193\n26/07/1986\n22/07/2014\n15/05/2016\n\n\nMarc Albrighton\n0.8038012\n18/11/1989\n1/07/2014\n15/05/2016\n\n\nMarcin Wasilewski\n0.0885965\n9/06/1980\n17/09/2013\n15/05/2016\n\n\nNathan Dyer\n0.0643275\n29/11/1987\n1/09/2015\n15/05/2016\n\n\nN'Golo Kante\n0.8836257\n29/03/1991\n3/08/2015\n15/05/2016\n\n\nRitchie De Laet\n0.1921053\n28/11/1988\n1/07/2012\n15/05/2016\n\n\nRiyad Mahrez\n0.8871345\n21/02/1991\n11/01/2014\n15/05/2016\n\n\nRobert Huth\n0.9210526\n18/08/1984\n1/07/2015\n15/05/2016\n\n\nShinji Okazaki\n0.6005848\n16/04/1986\n1/07/2015\n15/05/2016\n\n\nWes Morgan\n1.0000000\n21/01/1984\n30/01/2012\n15/05/2016\n\n\nYohan Benalouane\n0.0198830\n28/03/1987\n3/08/2015\n15/05/2016\n\n\n\n\n\n\n\n\n\nThe percent_involvement column is a 0 - 1 number representing the percentage of minutes played for the season.\nThe dob column is each players date of birth.\nThe arrival_at_team column is the date the player joined the club.\nThe reference_date column is the date that you want to calculate age and time at the club from. In this circumstance, I‚Äôve used the date of the last Premier League game of the 2015/16 season.\n\nI found Leicester City‚Äôs data from 2015/16 at transfermarkt.com.\nSave this file as a .csv in your working directory.\n\n\nFind a logo\nFind your team‚Äôs logo online (preferably high resolution .png image with a transparent background), and save it into your working directory. I found this one on Leicester City‚Äôs Wikipedia page.\n\n\n\n\n\n\n\nStep 2 | Load packages and import data\n\nR packages\nThe below packages need to be loaded at the beginning of your R script. If this is the first time using any of these packages on your computer, make sure you install them first (e.g.¬†install.packages(\"package_name\")).\nUsing different fonts in R can be tricky, particularly on Windows machines (like I use). If you want to use a non-standard font like I have and you‚Äôre unfamiliar with the setup, read this article by June Choe that walks you through it.\nLater in this post I‚Äôll be using a font called ‚ÄúURWGeometricW03-Light‚Äù that I had to download online, you‚Äôll need to substitute this in the code to a font available to you for the code to work (or aquire this font).\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggrepel)\nlibrary(ggforce)\nlibrary(magick)\nlibrary(scales)\n\n\n\nAdd metadata\nThis is where we define what will end up being used for our title, subtitle, caption, and logo.\n\n# Metadata ---------------------------------------------------------------\n\n# Title, subtitle, and legend\nteam_name &lt;- \"Leicester City\"\nshort_name &lt;- \"Foxes\"\nleague &lt;- \"English Premier League\"\nseason &lt;- \"2015/16\"\n\n# Caption\ndata_source &lt;- \"transfermarkt.com\"\nsocial_media_handle &lt;- \"@mitchhendo_\"\n\n# Name of logo file within working directory\nlogo_file_name &lt;- \"leicester_logo.png\"\n\n\n\nLoad data\nThis section will read in the data from my file called leicester_data.csv in my working directory, and make it an object called data. Then we tell R what kind of data certain columns are (number, date, character etc), and calculate a few new columns based on the data within the file.\nI‚Äôve added comments to the code so it‚Äôs easier to understand what each part is doing. Anything after a # is a comment which isn‚Äôt executed as code. Comments are used for explaining your code to others or yourself in the future.\n\n# Data import -------------------------------------------------------------\n\ndata &lt;- read_csv('data_leicester.csv') %&gt;% # Read in this file\n  mutate(\n    dob = dmy(dob),\n    # Recognise this column as a date\n    \n    reference_date = dmy(reference_date),\n    # Recognise this column as a date\n    \n    arrival_at_team = dmy(arrival_at_team),\n    # Recognise this column as a date\n    \n    age = (reference_date - dob) / 365,\n    # Create a new column that calculates each players age at the reference date\n    \n    age_at_arrival = (arrival_at_team - dob) / 365,\n    # Create a new column that calculates each players age at arrival to the club\n    \n    time_with_team = as_factor(ifelse(arrival_at_team &lt; reference_date - 365, \"Years &gt; 1\", \"Years &lt; 1\"))\n    # Create a new column that determines whether a player has been at the club for longer than a year or not\n  )\n\n\n\n\n\nStep 3 | Create plot\n\nPrep\nBefore we create the ggplot object, we need to define a few things to make the plotting easier.\nFirstly, we define what colours we want for the dots and call this object year_colours (using hex code to specify colours), and also define a series of numbers that we‚Äôll call index which will allow us to plot the trailing lines behind the players (showing how long they‚Äôve been at the club for).\n\n# Colours of the dots\nyear_colours &lt;- c(`Years &gt; 1` = \"#25ABF8\", `Years &lt; 1` = \"#CE3A6C\")\n\n# This vector is needed to draw the trailing lines showing how long a player has been at the club\n# Don't change this unless you know what you're doing\nindex &lt;- c(0, 0.25, 0.5, 0.75, 1)\n\n\n\nPlotting\nNow the fun begins. Let‚Äôs start building the plot.\nWe‚Äôll start by using the ggplot function and telling it that the data we‚Äôre using is from the data object we created earlier. The aes() function is used to specify what parts of our data are going to be used in the plot, so we say the x-axis will be our age column and the y-axis will be our percent_involvement column.\n\nggplot(data = data, aes(x = age, y = percent_involvement))\n\n\n\n\n\n\n\n\nThis is essentially the canvas that we‚Äôll build from.\nNext we‚Äôll add our dots using the geom_point() function. The way the ggplot function works is by adding layers (called geoms) to the ‚Äúcanvas‚Äù. We add layers or aspects to the plot by adding them with a +.\nNote I‚Äôve added another column from our dataset to specify the colour in the aes() function for the geom_point() layer only. The data specified in the aes() function at the top is applied to all geoms below unless specified otherwise within the an individual geom. I‚Äôve also manually adjusted the size of the dots, which is done outside the aes().\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4)\n\n\n\n\n\n\n\n\nNext we‚Äôll add our title, subtitle, x-axis title, caption, and legend title using the labs() function. All of the information for these has been defined in Step 2 where we added the metadata.\nThe paste0() function essentially allows us to paste together objects we‚Äôve defined using code and written character strings to create a character string that dynamically changes based on different inputs (e.g.¬†paste0(team_name, \" | Squad Age Profile\") becomes ‚ÄúLeicester City | Squad Age Profile‚Äù). You can use the dynamic titles like I have, or you could simply write what you want each part to say within quotation marks like I did for the x-axis title.\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name))\n\n\n\n\n\n\n\n\nNext we‚Äôll fix up our y-axis by using the scale_y_continuous() function to give it a proper title, use percent scales, and tell it where to break up the axis ticks.\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1))\n\n\n\n\n\n\n\n\nThen we set our axis limits using the expand_limits(), and x-axis breaks using scale_x_continuous().\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_x_continuous(breaks = seq(16, 40, 4))\n\n\n\n\n\n\n\n\nWe can add our colours to the dots that we specified earlier by using scale_colour_manual() and specifying the values to be our object year_colours.\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_colour_manual(values = year_colours)\n\n\n\n\n\n\n\n\nOne of the most fun parts of using ggplot in my mind is playing around with the theme. There are a number of basic themes built into ggplot aswell as some more fun ones that can be added with packages like hrbrthemes, ggtech (which has themes to imitate AirBnb, Facebook, Google and Twitter‚Äôs style), and ggthemes (which has themes to imitate plots made by FiveThirtyEight, Wall Street Journal, and The Economist among others). The best page I‚Äôve found for exploring different themes and theme packages is Themes to improve your ggplot figures by rfortherestofus.com. You can also modify themes any way you‚Äôd like using the theme() function which we‚Äôll get to next.\nI‚Äôll use theme_minimal() as a base.\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_colour_manual(values = year_colours) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nYou can adjust any aspect of the theme manually with theme(). The flexibility and power of this is almost endless, and far beyond the scope of this post, but carefully look through all the arguments I‚Äôve written and you‚Äôll be able to understand a lot of it.\nRemember that you will likely need to change the font (the family argument within theme()) where mine says URWGeometricW03-Light to a font available to you (fonts can be tricky, this post will help).\nFeel free to play around with these to get a different look or to get a better understanding of what they‚Äôre doing. For example, you could change the colour of the plot area (i.e.¬†where the data goes) by changing the hex code in plot.background = element_rect(fill = \"#141622\").\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_colour_manual(values = year_colours) +\n  theme_minimal() +\n  theme(legend.position = \"right\", \n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#141622\"),\n        panel.background = element_rect(fill = \"#141622\", \n                                        colour = \"#141622\",\n                                        size = 2, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.5, \n                                        linetype = 'solid',\n                                        colour = \"gray30\"),\n        axis.title.x = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.title.y = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.text.x = element_text(colour = \"white\"),\n        axis.text.y = element_text(colour = \"white\"),\n        plot.title = element_text(face = \"bold\", \n                                  colour = \"white\", \n                                  size = 14, \n                                  family = \"Century Gothic\"),\n        plot.subtitle = element_text(colour = \"white\", \n                                     family = \"URWGeometricW03-Light\", \n                                     size = 10),\n        plot.caption = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 10),\n        plot.caption.position = \"plot\",\n        legend.title = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 14),\n        legend.text = element_text(colour = \"white\", \n                                   family = \"URWGeometricW03-Light\", \n                                   size = 14))\n\n\n\n\n\n\n\n\nNext we add the player name labels to the plot using geom_text_repel() from the ggrepel package we loaded earlier. It‚Äôs a handy function that basically ensures labels don‚Äôt overlap each other.\nThe order in which we add things from here starts to matter now. Like I mentioned earlier, becuase ggplot‚Äôs are built with layers, you need to think about what order you want them laid. I want the labels to be added on top of the dots, so I‚Äôll put this geom right after geom_point().\nAgain, in my code below, this geom uses the ‚ÄúURWGeometricW03-Light‚Äù font I got online. You‚Äôll need to download this font or change it to a font available to you.\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  geom_text_repel(aes(label = player_name), \n                  size = 3.25, \n                  colour = \"white\", \n                  family = \"URWGeometricW03-Light\") +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_colour_manual(values = year_colours) +\n  theme_minimal() +\n  theme(legend.position = \"right\", \n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#141622\"),\n        panel.background = element_rect(fill = \"#141622\", \n                                        colour = \"#141622\",\n                                        size = 2, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.5, \n                                        linetype = 'solid',\n                                        colour = \"gray30\"),\n        axis.title.x = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.title.y = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.text.x = element_text(colour = \"white\"),\n        axis.text.y = element_text(colour = \"white\"),\n        plot.title = element_text(face = \"bold\", \n                                  colour = \"white\", \n                                  size = 14, \n                                  family = \"Century Gothic\"),\n        plot.subtitle = element_text(colour = \"white\", \n                                     family = \"URWGeometricW03-Light\", \n                                     size = 10),\n        plot.caption = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 10),\n        plot.caption.position = \"plot\",\n        legend.title = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 14),\n        legend.text = element_text(colour = \"white\", \n                                   family = \"URWGeometricW03-Light\", \n                                   size = 14))\n\n\n\n\n\n\n\n\nThe plot is really starting to look like the finished product now.\nWe need to add the trailing white lines with the geom_link() function from the ggforce package we‚Äôve loaded. Again, the order is important here, we want the lines to be beneath the dots so we add this geom before geom_point().\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  geom_link(aes(x = age_at_arrival,\n                xend = age,\n                yend = percent_involvement,\n                alpha = stat(index)), \n            colour = \"white\", \n            lineend = \"round\",\n            show.legend = F) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  geom_text_repel(aes(label = player_name), \n                  size = 3.25, \n                  colour = \"white\", \n                  family = \"URWGeometricW03-Light\") +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_colour_manual(values = year_colours) +\n  theme_minimal() +\n  theme(legend.position = \"right\", \n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#141622\"),\n        panel.background = element_rect(fill = \"#141622\", \n                                        colour = \"#141622\",\n                                        size = 2, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.5, \n                                        linetype = 'solid',\n                                        colour = \"gray30\"),\n        axis.title.x = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.title.y = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.text.x = element_text(colour = \"white\"),\n        axis.text.y = element_text(colour = \"white\"),\n        plot.title = element_text(face = \"bold\", \n                                  colour = \"white\", \n                                  size = 14, \n                                  family = \"Century Gothic\"),\n        plot.subtitle = element_text(colour = \"white\", \n                                     family = \"URWGeometricW03-Light\", \n                                     size = 10),\n        plot.caption = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 10),\n        plot.caption.position = \"plot\",\n        legend.title = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 14),\n        legend.text = element_text(colour = \"white\", \n                                   family = \"URWGeometricW03-Light\", \n                                   size = 14))\n\n\n\n\n\n\n\n\nNow we need to add the green Peak Years area and label. This is done with annotate() which manually adds things like shapes, text, or images. We‚Äôre adding a shape (rect for rectangle) and text, so we add 2 annotate() geoms before anything else (because we want them to be at the deepest layer), and provide it the coordinates so it knows where to put them.\nOnce again, change family if you don‚Äôt have the ‚ÄúURWGeometricW03-Light‚Äù font.\n\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  annotate(\"rect\", \n           xmin = 24,\n           xmax = 29,\n           ymin = -Inf,\n           ymax = 1,\n           alpha = 0.5,\n           fill = \"mediumseagreen\") +\n  annotate(\"text\", \n           x = 26.5, \n           y = 1.05, \n           label = \"Peak Years\", \n           colour = \"mediumseagreen\", \n           alpha = 0.7, \n           family = \"URWGeometricW03-Light\",\n           size = 5) +\n  geom_link(aes(x = age_at_arrival,\n                xend = age,\n                yend = percent_involvement,\n                alpha = stat(index)), \n            colour = \"white\", \n            lineend = \"round\",\n            show.legend = F) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  geom_text_repel(aes(label = player_name), \n                  size = 3.25, \n                  colour = \"white\", \n                  family = \"URWGeometricW03-Light\") +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_colour_manual(values = year_colours) +\n  theme_minimal() +\n  theme(legend.position = \"right\", \n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#141622\"),\n        panel.background = element_rect(fill = \"#141622\", \n                                        colour = \"#141622\",\n                                        size = 2, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.5, \n                                        linetype = 'solid',\n                                        colour = \"gray30\"),\n        axis.title.x = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.title.y = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.text.x = element_text(colour = \"white\"),\n        axis.text.y = element_text(colour = \"white\"),\n        plot.title = element_text(face = \"bold\", \n                                  colour = \"white\", \n                                  size = 14, \n                                  family = \"Century Gothic\"),\n        plot.subtitle = element_text(colour = \"white\", \n                                     family = \"URWGeometricW03-Light\", \n                                     size = 10),\n        plot.caption = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 10),\n        plot.caption.position = \"plot\",\n        legend.title = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 14),\n        legend.text = element_text(colour = \"white\", \n                                   family = \"URWGeometricW03-Light\", \n                                   size = 14))\n\n\n\n\n\n\n\n\n\n\n\n\nStep 4 | Saving and adding the logo\n\nSaving the plot\nTo save the plot as a high resolution image we can use the ggsave() function. Here I save the file with a dynamic name that equates to the current date, underscore, short_name (object we created in Step 2 = ‚ÄúFoxes‚Äù), underscore, peak-years.png. So for me, today as I write this post, the file would be saved as 2020-04-24_Foxes_peak-years.png, but that would be different if I was to save it on a different day or with a different short_name object.\nThe dpi argument is dots per inch and allows you to set the resolution. Higher is better but also means a larger file size (dpi = 600 is good).\nThe file will be saved into your working directory.\n\nggsave(paste0(Sys.Date(), \"_\", short_name, \"_peak-years.png\"), \n       height = 5.75,\n       width = 7.25,\n       dpi = 600)\n\n\n\nAdding the logo\nThere‚Äôs a number of ways to add a logo to a ggplot object, but they can be quite complex. The best one I‚Äôve found is using a custom function that Thomas Mock created and posted on his blog.\nIt reads in the plot as a .png image, the logo as another .png image, and puts the logo in a corner you specify at a size you specify.\nThe only parts of this you may want to modify are the sections below ### ONLY MODIFY FROM HERE DOWN. You can choose which corner you want the logo in, what is the file name you saved the plot image, and the size of the logo (bigger number = smaller logo).\n\n# Add logo function -------------------------------------------------------\n\nadd_logo &lt;- function(plot_path, logo_path, logo_position, logo_scale = 10){\n  \n  # Requires magick R Package https://github.com/ropensci/magick\n  \n  # Useful error message for logo position\n  if (!logo_position %in% c(\"top right\", \"top left\", \"bottom right\", \"bottom left\")) {\n    stop(\"Error Message: Uh oh! Logo Position not recognized\\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'\")\n  }\n  \n  # read in raw images\n  plot &lt;- magick::image_read(plot_path)\n  logo_raw &lt;- magick::image_read(logo_path)\n  \n  # get dimensions of plot for scaling\n  plot_height &lt;- magick::image_info(plot)$height\n  plot_width &lt;- magick::image_info(plot)$width\n  \n  # default scale to 1/10th width of plot\n  # Can change with logo_scale\n  logo &lt;- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))\n  \n  # Get width of logo\n  logo_width &lt;- magick::image_info(logo)$width\n  logo_height &lt;- magick::image_info(logo)$height\n  \n  # Set position of logo\n  # Position starts at 0,0 at top left\n  # Using 0.01 for 1% - aesthetic padding\n  \n  if (logo_position == \"top right\") {\n    x_pos = plot_width - logo_width - 0.02 * plot_width\n    y_pos = 0.01 * plot_height\n  } else if (logo_position == \"top left\") {\n    x_pos = 0.01 * plot_width\n    y_pos = 0.01 * plot_height\n  } else if (logo_position == \"bottom right\") {\n    x_pos = plot_width - logo_width - 0.02 * plot_width\n    y_pos = plot_height - logo_height - 0.02 * plot_height\n  } else if (logo_position == \"bottom left\") {\n    x_pos = 0.01 * plot_width\n    y_pos = plot_height - logo_height - 0.02 * plot_height\n  }\n  \n  # Compose the actual overlay\n  magick::image_composite(plot, logo, offset = paste0(\"+\", x_pos, \"+\", y_pos))\n  \n}\n\n\n### ONLY MODIFY FROM HERE DOWN\n\n# Choose logo, position, and size (bigger number = smaller logo) ----------\n\nplot_with_logo &lt;- add_logo(\n  plot_path = paste0(Sys.Date(), \"_\", short_name, \"_peak-years.png\"), # url or local file for the plot\n  logo_path = logo_file_name, # url or local file for the logo\n  logo_position = \"top right\", # choose a corner\n  # 'top left', 'top right', 'bottom left' or 'bottom right'\n  logo_scale = 7\n)\n\n# save the image and write to working directory\nmagick::image_write(plot_with_logo, paste0(Sys.Date(), \"_\", short_name, \"_peak-years.png\"))\n\nThis‚Äôll save over the file we created with a new file that‚Äôs the plot image with the logo added like this:\n\nAnd that‚Äôs it! Let me know if you have any questions or want me to clarify anything.\nKeep up to date with anything new from me on my Twitter.\nCheers,\nMitch\n\n\n\nFull code\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggrepel)\nlibrary(ggforce)\nlibrary(magick)\nlibrary(scales)\n\n\n# Metadata ---------------------------------------------------------------\n\n# Title, subtitle, and legend\nteam_name &lt;- \"Leicester City\"\nshort_name &lt;- \"Foxes\"\nleague &lt;- \"English Premier League\"\nseason &lt;- \"2015/16\"\n\n# Caption\ndata_source &lt;- \"transfermarkt.com\"\nsocial_media_handle &lt;- \"@mitchhendo_\"\n\n# Name of logo file within working directory\nlogo_file_name &lt;- \"leicester_logo.png\"\n\n\n\n# Data import -------------------------------------------------------------\n\ndata &lt;- read_csv('data_leicester.csv') %&gt;% # Read in this file\n  mutate(\n    dob = dmy(dob),\n    # Recognise this column as a date\n    \n    reference_date = dmy(reference_date),\n    # Recognise this column as a date\n    \n    arrival_at_team = dmy(arrival_at_team),\n    # Recognise this column as a date\n    \n    age = (reference_date - dob) / 365,\n    # Create a new column that calculates each players age at the reference date\n    \n    age_at_arrival = (arrival_at_team - dob) / 365,\n    # Create a new column that calculates each players age at arrival to the club\n    \n    time_with_team = as_factor(ifelse(arrival_at_team &lt; reference_date - 365, \"Years &gt; 1\", \"Years &lt; 1\"))\n    # Create a new column that determines whether a player has been at the club for longer than a year or not\n  )\n\n\n# Visualise ---------------------------------------------------------------\n\n# Colours of the dots\nyear_colours &lt;- c(`Years &gt; 1` = \"#25ABF8\", `Years &lt; 1` = \"#CE3A6C\")\n\n# This vector is needed to draw the trailing lines showing how long a player has been at the club\n# Don't change this unless you know what you're doing\nindex &lt;- c(0, 0.25, 0.5, 0.75, 1)\n\n\n# Construct plot\nggplot(data = data, aes(x = age, y = percent_involvement)) +\n  annotate(\"rect\", xmin = 24, xmax = 29, ymin = -Inf, ymax = 1, alpha = 0.5, fill = \"mediumseagreen\") +\n  annotate(\"text\", \n           x = 26.5, \n           y = 1.05, \n           label = \"Peak Years\", \n           colour = \"mediumseagreen\", \n           alpha = 0.7, \n           family = \"URWGeometricW03-Light\",\n           size = 5) +\n  geom_link(aes(x = age_at_arrival, xend = age, yend = percent_involvement, alpha = stat(index)), \n            colour = \"white\", \n            lineend = \"round\",\n            show.legend = F) +\n  geom_point(aes(colour = time_with_team), size = 4) +\n  geom_text_repel(aes(label = player_name), \n                  size = 3.25, \n                  colour = \"white\", \n                  family = \"URWGeometricW03-Light\") +\n  labs(x = \"Age\",\n       title = paste0(team_name, \" | Squad Age Profile\"), \n       subtitle = paste0(league, \" | Season \", season),\n       caption = paste0(social_media_handle, \" | Data: \", data_source),\n       colour = paste0(\"Time at \", short_name)) +\n  scale_y_continuous(\"Share of minutes played\", \n                     labels = scales::percent_format(accuracy = 1), \n                     breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +\n  expand_limits(x = c(16, 40), y = c(0, 1)) +\n  scale_x_continuous(breaks = seq(16, 40, 4)) +\n  scale_colour_manual(values = year_colours) +\n  theme_minimal() +\n  theme(legend.position = \"right\", \n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"#141622\"),\n        panel.background = element_rect(fill = \"#141622\", \n                                        colour = \"#141622\",\n                                        size = 2, \n                                        linetype = \"solid\"),\n        panel.grid.major = element_line(size = 0.5, \n                                        linetype = 'solid',\n                                        colour = \"gray30\"),\n        axis.title.x = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.title.y = element_text(size = 13, \n                                    face = \"bold\", \n                                    colour = \"white\", \n                                    family = \"Century Gothic\"),\n        axis.text.x = element_text(colour = \"white\"),\n        axis.text.y = element_text(colour = \"white\"),\n        plot.title = element_text(face = \"bold\", \n                                  colour = \"white\", \n                                  size = 14, \n                                  family = \"Century Gothic\"),\n        plot.subtitle = element_text(colour = \"white\", \n                                     family = \"URWGeometricW03-Light\", \n                                     size = 10),\n        plot.caption = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 10),\n        plot.caption.position = \"plot\",\n        legend.title = element_text(colour = \"white\", \n                                    family = \"URWGeometricW03-Light\", \n                                    size = 14),\n        legend.text = element_text(colour = \"white\", \n                                   family = \"URWGeometricW03-Light\", \n                                   size = 14)) +\n  ggsave(paste0(Sys.Date(), \"_\", short_name, \"_peak-years.png\"),  dpi = 600)\n\n\n\n\n\n# Add logo function -------------------------------------------------------\n\nadd_logo &lt;- function(plot_path, logo_path, logo_position, logo_scale = 10){\n  \n  # Requires magick R Package https://github.com/ropensci/magick\n  \n  # Useful error message for logo position\n  if (!logo_position %in% c(\"top right\", \"top left\", \"bottom right\", \"bottom left\")) {\n    stop(\"Error Message: Uh oh! Logo Position not recognized\\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'\")\n  }\n  \n  # read in raw images\n  plot &lt;- magick::image_read(plot_path)\n  logo_raw &lt;- magick::image_read(logo_path)\n  \n  # get dimensions of plot for scaling\n  plot_height &lt;- magick::image_info(plot)$height\n  plot_width &lt;- magick::image_info(plot)$width\n  \n  # default scale to 1/10th width of plot\n  # Can change with logo_scale\n  logo &lt;- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))\n  \n  # Get width of logo\n  logo_width &lt;- magick::image_info(logo)$width\n  logo_height &lt;- magick::image_info(logo)$height\n  \n  # Set position of logo\n  # Position starts at 0,0 at top left\n  # Using 0.01 for 1% - aesthetic padding\n  \n  if (logo_position == \"top right\") {\n    x_pos = plot_width - logo_width - 0.02 * plot_width\n    y_pos = 0.01 * plot_height\n  } else if (logo_position == \"top left\") {\n    x_pos = 0.01 * plot_width\n    y_pos = 0.01 * plot_height\n  } else if (logo_position == \"bottom right\") {\n    x_pos = plot_width - logo_width - 0.01 * plot_width\n    y_pos = plot_height - logo_height - 0.01 * plot_height\n  } else if (logo_position == \"bottom left\") {\n    x_pos = 0.01 * plot_width\n    y_pos = plot_height - logo_height - 0.01 * plot_height\n  }\n  \n  # Compose the actual overlay\n  magick::image_composite(plot, logo, offset = paste0(\"+\", x_pos, \"+\", y_pos))\n  \n}\n\n\n\n# Choose logo, position, and size (bigger number = smaller logo) ----------\n\nplot_with_logo &lt;- add_logo(\n  plot_path = paste0(Sys.Date(), \"_\", short_name, \"_peak-years.png\"), # url or local file for the plot\n  logo_path = logo_file_name, # url or local file for the logo\n  logo_position = \"top right\", # choose a corner\n  # 'top left', 'top right', 'bottom left' or 'bottom right'\n  logo_scale = 7\n)\n\n# save the image and write to working directory\nmagick::image_write(plot_with_logo, paste0(Sys.Date(), \"_\", short_name, \"_peak-years.png\"))"
  },
  {
    "objectID": "posts/2020-04-05_Tidy-Catapult-10Hz.html",
    "href": "posts/2020-04-05_Tidy-Catapult-10Hz.html",
    "title": "Tidying Catapult 10Hz export data",
    "section": "",
    "text": "You can see me going through all the steps outlined here in this video with some dummy data (note that I‚Äôve simplified the file structure in the post since recording this video so it will be a little different; both work though):"
  },
  {
    "objectID": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-1",
    "href": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-1",
    "title": "Tidying Catapult 10Hz export data",
    "section": "Step 1",
    "text": "Step 1\nCreate a folder that will contain all your folders of Openfield 10Hz exports. Name this anything you like.\nThis folder will need to be in your working directory when you run the code below. If you aren‚Äôt familiar with a working directory, it is just a file path on your computer that sets the default location of any files you read into R, or save out of R. Think of it like a ‚Äúhome‚Äù folder and you refer to all files relative to this (you can check what it‚Äôs currently set to by running getwd(). I recommend using RStudio Projects to make this process much smoother.\nIn my code below I‚Äôve assigned the variable folder_name to be ‚Äúcombine‚Äù (the name of my folder that I will save the export files). You will need to change the folder_name variable to the folder that will contain your export files."
  },
  {
    "objectID": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-2",
    "href": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-2",
    "title": "Tidying Catapult 10Hz export data",
    "section": "Step 2",
    "text": "Step 2\nExport the files you‚Äôd like to combine from Openfield without changing their filename and save them in the folder discussed in Step 1.\nSome examples could be ‚ÄúRound 1‚Äù if you‚Äôre combining all your athletes exports from a round 1 match."
  },
  {
    "objectID": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-3",
    "href": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-3",
    "title": "Tidying Catapult 10Hz export data",
    "section": "Step 3",
    "text": "Step 3\nMake sure you have R and RStudio downloaded and installed on your machine (both free!).\nOpen RStudio, copy and paste the code below into a script (you can create a new R script by clicking the symbol directly under ‚ÄòFile‚Äô on the top-left of the window, and selecting ‚ÄòR Script‚Äô).\nSave the file as a .R file with an appropriate name (e.g.¬†‚Äútidy_catapult_data.R‚Äù).\n\n# Script to combine and tidy multiple Catapult Openfield 10Hz export .csv files by Mitch Henderson\n\nlibrary(tidyverse)\nlibrary(zoo)\n\n# This must exactly match the folder name containing the .csv files and be in your working directory\n\nfolder_name &lt;- \"combine\"\n\n# This function will read in multiple .csv files, create a column with the file name, and parse it into it's relevant components.\n\nread_plus &lt;- function(flnm) {\n  read_csv(flnm, skip = 8) |&gt;\n    mutate(Filename = flnm,\n           without_folder = str_split(Filename, \"/\")[[1]][2],\n           Activity = str_split(without_folder, \" Export\")[[1]][1],\n           Player_interim = str_split(without_folder, \" for \")[[1]][2],\n           Player = paste0(\n             str_split(Player_interim, \" \")[[1]][1],\n             \" \",\n             str_split(Player_interim, \" \")[[1]][2]\n             )\n           ) |&gt;\n  select(-Filename,\n         -Player_interim,\n         -without_folder)\n}\n\n# Import all files contained within the folder specified by `folder_name` above\n\ncombine_and_tidy &lt;-\n  list.files(path = paste0(folder_name, \"/\"),\n             pattern = \"*.csv\", \n             full.names = T) |&gt;\n  map_df(~read_plus(.))\n\n# Output csv into working directory\n\nwrite.csv(combine_and_tidy, file = paste0(folder_name, \"_tidy.csv\"), row.names = F)"
  },
  {
    "objectID": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-4",
    "href": "posts/2020-04-05_Tidy-Catapult-10Hz.html#step-4",
    "title": "Tidying Catapult 10Hz export data",
    "section": "Step 4",
    "text": "Step 4\nChange the folder_name variable to the exact folder name (in double quotes like is currently in the code) containing the .csv files you would like to combine and tidy.\nHighlight the entire code and press Ctrl + Enter on PC or Cmd + Return on a Mac. This will run the code and produce the output .csv file in your working directory.\nDone!\nNow the data is in tidy format and is easy to manipulate and analyse!\n\n\nLet me know if this post has helped you or if there‚Äôs anything else you‚Äôre interested in learning that I can help with. I‚Äôm keen to hear!\nKeep up to date with anything new from me on my Twitter.\nCheers,\nMitch\nThumbnail from catapultsports.com."
  },
  {
    "objectID": "posts/2020-05-19_heidi-post.html",
    "href": "posts/2020-05-19_heidi-post.html",
    "title": "Visualising Apple Health data |Guest post by Heidi Thornton",
    "section": "",
    "text": "As sports scientists during the COVID-19 shutdown, we have limited ways of determining adherence to training programs (completed within govenment guidelines of course!).\nData from smart watches provide practitioners with basic measures that can be used as a rough guide to quantify training over this period (when using the more sophisticated technologies isn‚Äôt possible).\nAlthough the reliability and validity data of these devices aren‚Äôt widely available, they provide basic metrics such as total distance, duration, heart rate, and energy burnt etc.\nIn this post I‚Äôll run through how to:\nYou can find presentation slides covering all content and the full code at the end of the post."
  },
  {
    "objectID": "posts/2020-05-19_heidi-post.html#step-1",
    "href": "posts/2020-05-19_heidi-post.html#step-1",
    "title": "Visualising Apple Health data |Guest post by Heidi Thornton",
    "section": "Step 1",
    "text": "Step 1\nOpen the Apple Health app on your phone, then summary page at the top right, then tap the circle showing the first letter of your first name on the top right (left figure above)."
  },
  {
    "objectID": "posts/2020-05-19_heidi-post.html#step-2",
    "href": "posts/2020-05-19_heidi-post.html#step-2",
    "title": "Visualising Apple Health data |Guest post by Heidi Thornton",
    "section": "Step 2",
    "text": "Step 2\nSlide down and tap ‚ÄòExport All Health Data‚Äô (middle figure)."
  },
  {
    "objectID": "posts/2020-05-19_heidi-post.html#step-3",
    "href": "posts/2020-05-19_heidi-post.html#step-3",
    "title": "Visualising Apple Health data |Guest post by Heidi Thornton",
    "section": "Step 3",
    "text": "Step 3\nThe export takes up to a few minutes, then a page to email or message it will pop up. Email this file to yourself and download it.\nIf you don‚Äôt have an Apple watch and want to use my data, you can download my .xml file here."
  },
  {
    "objectID": "posts/2021-02-04-exploring-catapults-running-symmetry-data.html",
    "href": "posts/2021-02-04-exploring-catapults-running-symmetry-data.html",
    "title": "Exploring Catapult‚Äôs running imbalance data",
    "section": "",
    "text": "An interesting metric available in the Catapult system is running imbalance.\nCatapult‚Äôs Openfield software offers running symmetry metrics that try to quantify the load imbalance between the right and left leg when running. Detailed information about the running symmetry metrics and how to set them up is available in the Catapult Support documentation.\nThe documentation claims the practical applications of running symmetry metrics include:\n\nRehabilitation - See changes over time as the athlete improves during the process of rehabilitation\nReturn to Play - Use Running Symmetry as an objective return to play marker\nAthlete Screening - Use Running Symmetry on a weekly basis to identify changes in running mechanics\n\nRunning imbalance (%), arguably the most general running symmetry metric, is defined by Catapult as:\n\n‚ÄúAverage percentage load difference between left and right legs, across all Running Symmetry Series/Efforts. A negative running imbalance % is indicative of an x% additional load on the left side (where x is the running imbalance value). A positive running imbalance % is indicative of an x% additional load on the right side (where x is the running imbalance value).‚Äù\n\nWhilst I do have concerns about some of the measurement properties of this metric and don‚Äôt currently use it in practice for these reasons, I wanted to explore the data and see what it‚Äôs telling me. This post will show you how to export the data from Openfield Cloud, and visualise it using R and RStudio.\n\nThe full un-separated code is available at the end of this post for anyone looking to copy it into their script.\n\nStep 1 | Export from Openfield Cloud\nFirst thing to do is follow the steps outlined in the Catapult Support documentation to set up running symmetry metrics.\nFor a reason beyond my knowledge, when you perform a bulk export from Openfield Cloud with ‚ÄòAll Parameters‚Äô selected (when choosing a parameter group), you get an inconsistent number of columns in the .csv exports (if anyone knows why this might be, I‚Äôm interested to know!). This causes issues when we try to import and join the data into one data frame (i.e.¬†table of data) in R.\nTo remedy this, we need to create a parameter group to lock the columns that we want in our exports (ensuring a consistent export format).\n\nCreate a parameter group\nAfter logging into Openfield Cloud, press Settings\n\nSelect Parameters in the sidebar, then Parameter Groups in the top bar.\n\nNow we need to Add new.\n\nWe can give the group we‚Äôre creating a name (I‚Äôm calling mine ‚ÄúImbalance‚Äù) and select the metrics we‚Äôre interested in (I‚Äôm only selecting ‚ÄúDate‚Äù and ‚ÄúRunning Imbalance‚Äù). Then we click the orange Add Parameter Group at the bottom of the window to save our new group.\n\n\n\nSelect sessions to export\nThe Activities bar on the left of screen can be used to select multiple sessions that we‚Äôre interested in exporting data for. Using the click buttons on the right on the bar, we can select one or more years, months, days, or activities to export (I‚Äôve selected all of 2021 below).\n\nWhen more than one activity is selected, a green Bulk Export CTRs button will become available in the top right of screen (also showing how many activities have been selected). Click on it.\n\nThis will bring up a window allowing us to select some options for our exports. The only things we need to do is select our newly created parameter group (I‚Äôm selecting ‚ÄúImbalance‚Äù below) and enter the email you‚Äôd like the links for the exports to go to. Then select Export Bulk CTR.\n\n\n\nDownload exports\nYou‚Äôll then shortly receive one or more emails (depending on how many activities, and therefore data, you‚Äôre exporting) from Openfield Web with links to download .zip folders containing the exports.\n\n\n\n\nStep 2 | Import into RStudio\nSave all of your exports (keep them in .csv format) in a folder within your working directory (you can check your working directory in R or RStudio by running getwd() and you can change it with setwd(), but I‚Äôd recommend creating a project so it‚Äôs set for you). I‚Äôve called my folder ‚ÄúExports‚Äù.\n\nLoad packages\nOpen RStudio, and create a new R script (I recommend saving it with an appropriate name straight away).\nBelow are the packages we‚Äôll need for this process. I‚Äôve already installed them, so I‚Äôm only loading them here (and have commented out the installation commands at the top), but if you haven‚Äôt previously installed them then you‚Äôll need to delete the hashtags at the beginning of the lines and run the top parts first (only needs to be done once). The install might take a while (minutes, not hours), and you might need to follow some prompts in the R console (bottom left window of RStudio) for the process to fully complete.\nNote that I‚Äôm using a Windows computer (hence the device = \"win\" component of the code). I believe R works much better with fonts on Macs and this part of that line isn‚Äôt required (extrafont::loadfonts() should work, I‚Äôm interested to know if anyone reading is using a Mac).\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggtext)\nlibrary(here)\n\n\n\nImport files\nNow, assuming you have a folder of your exports in your working directory (I have all mine in a folder called ‚ÄúExports‚Äù), we can use a combination of the read_csv() and list.files() functions to:\n\nImport all files within your folder that include .csv in their filename into RStudio at once\nSkip the first 9 lines (which is metadata we don‚Äôt need)\nJoin them all together and call this data frame ‚Äúdata‚Äù\nFilter away any period-level data so only activity-level rows remains (i.e.¬†session totals)\n\nWe‚Äôll also select() only the Date, Player Name, and Running Imbalance columns (all others are discarded), and use mutate() with dmy() to tell R that our Date variable should be in a date format.\n\ndata &lt;-\n  list.files(path = here(\"Exports\"),\n             pattern = \"*.csv\", \n             full.names = T) %&gt;%\n  map_df(~read_csv(., skip = 9)) %&gt;%\n  filter(`Period Name` == \"Session\") %&gt;% \n  select(`Date`,\n         `Player Name`,\n         `Running Imbalance`) %&gt;%\n  mutate(Date = dmy(Date))\n\nFor everyone following along that uses the Catapult system and can access their team‚Äôs data, the code above is what‚Äôs required to import all your data into R. For those that just want to follow along with some dummy data in the same format, you can click here to download my example .csv file.\nFor privacy reasons, I‚Äôll continue the tutorial using the dummy data contained in my .csv file. Note that all code from Step 3 onwards works on data imported either way (i.e.¬†from either your own Openfield exports (method above) or my example .csv (method below)).\nThe import for the .csv file is much simpler:\n\ndata &lt;- read_csv(\"example_running_imbalance_data.csv\") %&gt;%\n  mutate(Date = dmy(Date))\n\nThe first 6 rows of data (251 rows, 3 columns in total) look like this:\n\n\n\n\n\nDate\nPlayer Name\nRunning Imbalance\n\n\n\n\n2020-07-06\nPlayer Q\n0.94264\n\n\n2020-07-06\nPlayer Q\n-1.23166\n\n\n2020-07-07\nPlayer Q\n0.87172\n\n\n2020-07-10\nPlayer Q\n-0.88351\n\n\n2020-07-13\nPlayer Q\n-0.90294\n\n\n2020-07-13\nPlayer Q\n-0.24748\n\n\n\n\n\n\n\n\n\n\nStep 3 | Visualise using {ggplot2}\nIt‚Äôs beyond the scope of this post to go into full details of what each part of this ggplot2 code is doing (I have done this for a previous post where I built a more sophisticated chart step-by-step for those interested).\nIn an attempt to avoid telling you all to just ‚Äúdraw the rest of the damn owl‚Äù, I‚Äôll heavily comment my code so the purpose of all major functions are clear (context for the owl meme reference).\n\n\n# Create an object called min_date representing the minimum value in my `Date` column\n# Same thing for max_date with maximum value\n\nmin_date &lt;- min(data$Date)\nmax_date &lt;- max(data$Date)\n\n# We're taking the object called `data` and creating a ggplot with `Date` on the x-axis and\n# `Running Imbalance` on the y-axis\n\ndata %&gt;%\n  ggplot(aes(x = Date, y = `Running Imbalance`)) +\n  \n# Put a coloured rectangle that spans the width of the plot, and from -5% to 5% on the y-axis. \n  \n  annotate(\"rect\", \n           xmin = min_date, xmax = max_date, ymin = -5, ymax = 5, \n           alpha = .1, fill = \"#3A86FF\") +\n  \n# Create a text string that says \"Left / Right side bias\" with an arrow in the specified location.  \n  annotate(\"text\", x = min_date + 8.5, y = -7.5, \n           label = paste0(\"Left side bias \", sprintf('\\u2193')), \n           size = 3.5, colour = \"grey45\", family = \"Segoe UI\") +\n  \n  annotate(\"text\", x = min_date + 9.25, y = 8, \n           label = paste0(\"Right side bias \", sprintf('\\u2191')), \n           size = 3.5, colour = \"grey45\", family = \"Segoe UI\") +\n  \n# Facet the chart so each player in the `Player Name` column will have their own chart\n  \n  facet_wrap(~`Player Name`) +\n  \n# Create a horizontal line through the middle of each chart \n  \n  geom_hline(yintercept = 0, size = 1) +\n  \n# Add dots that represent each data point\n  \n  geom_point() +\n  \n# Add a smoothed conditional mean line through the data points to aid the eye in seeing patterns.\n  \n  geom_smooth(se = F, size = 2, colour = \"#F72585\") +\n  \n# Remove x axis title; add chart title, subtitle, caption, and y-axis title\n# Note the {ggtext} package allows us to use a little HTML to get coloured text!\n  \n  labs(x = NULL, y = \"**Running Imbalance (%)**\", \n       title = \"Running symmetry metrics can be used to monitor changes in running mechanics\", \n       subtitle = \"Session running imbalance **values** and \n       &lt;span style = 'color:#F72585;'&gt;**trends**&lt;/span&gt; \n       in relation to &lt;span style = 'color:#3A86FF;'&gt;**normal variation**&lt;/span&gt;\n     between players\",\n       caption = \"Data: Catapult Vector GPS Units\") +\n  \n# Give the chart a particular look using themes and theme options.\n# I've removed unnecessary parts, changed the font, and made some parts bold.\n  \n  theme_minimal() +\n  theme(text = element_text(family = \"Segoe UI\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_blank(),\n        axis.title.y = element_markdown(size = 12),\n        strip.text = element_markdown(face = \"bold\"),\n        axis.text.x = element_blank(),\n        plot.title = element_markdown(face = \"bold\", size = 18),\n        plot.subtitle = element_markdown(size = 14)) +\n  \n# Save the output in our working directory.  \n  \n  ggsave(\"left_vs_right.png\", width = 10.7, height = 5.75)\n\n\nAnd that‚Äôs it! Let me know if you have any questions or want me to clarify anything. Very interested to hear your ideas about running symmetry / imbalance data and how it can be best visualised / presented.\nIf the interest is there, I can do a video walkthrough of this process (similar to my others on constructing a ggplot and tidying data).\nKeep up to date with anything new from me on my Twitter.\n\nCheers,\nMitch\n\nThumbnail from Catapult\n\n\nFull code\n\n# Load packages -----------------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggtext)\nlibrary(here)\n\n# Import ------------------------------------------------------------------\n\n# Full import method using your own exports from Openfield ‚Üì\n\ndata &lt;-\n  list.files(path = here(\"Exports\"),\n             pattern = \"*.csv\", \n             full.names = T) %&gt;%\n  map_df(~read_csv(., skip = 9)) %&gt;%\n  filter(`Period Name` == \"Session\") %&gt;% \n  select(`Date`,\n         `Player Name`,\n         `Running Imbalance`) %&gt;%\n  mutate(Date = dmy(Date))\n\n# Import method using my `.csv` file that can be downloaded on my post ‚Üì\n\ndata &lt;- read_csv(\"example_running_imbalance_data.csv\") %&gt;%\n  mutate(Date = dmy(Date))\n\n# Visualise -------------------------------------------------------------------\n\nmin_date &lt;- min(data$Date)\nmax_date &lt;- max(data$Date)\n\n\ndata %&gt;%\n  ggplot(aes(x = Date, y = `Running Imbalance`)) +\n  annotate(\"rect\", \n           xmin = min_date, xmax = max_date, ymin = -5, ymax = 5, \n           alpha = .1, fill = \"#3A86FF\") +\n  annotate(\"text\", x = min_date + 8.5, y = -7.5, \n           label = paste0(\"Left side bias \", sprintf('\\u2193')), \n           size = 3.5, colour = \"grey45\", family = \"Segoe UI\") +\n  annotate(\"text\", x = min_date + 9.25, y = 8, \n           label = paste0(\"Right side bias \", sprintf('\\u2191')), \n           size = 3.5, colour = \"grey45\", family = \"Segoe UI\") +\n  facet_wrap(~`Player Name`) +\n  geom_hline(yintercept = 0, size = 1) +\n  geom_point() +\n  geom_smooth(se = F, size = 2, colour = \"#F72585\") +\n  labs(x = NULL, y = \"**Running Imbalance (%)**\", \n       title = \"Running symmetry metrics can be used to monitor changes in running mechanics\", \n       subtitle = \"Session running imbalance **values** and \n       &lt;span style = 'color:#F72585;'&gt;**trends**&lt;/span&gt; \n       in relation to &lt;span style = 'color:#3A86FF;'&gt;**normal variation**&lt;/span&gt;\n     between players\",\n       caption = \"Data: Catapult Vector GPS Units\") +\n  theme_minimal() +\n  theme(text = element_text(family = \"Segoe UI\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major.x = element_blank(),\n        axis.title.y = element_markdown(size = 12),\n        strip.text = element_markdown(face = \"bold\"),\n        axis.text.x = element_blank(),\n        plot.title = element_markdown(face = \"bold\", size = 18),\n        plot.subtitle = element_markdown(size = 14)) +\n  ggsave(\"left_vs_right.png\", width = 10.7, height = 5.75)"
  },
  {
    "objectID": "posts/2025-01-18-how-many-wins-do-nrl-teams-need-to-make-the-finals/index.html",
    "href": "posts/2025-01-18-how-many-wins-do-nrl-teams-need-to-make-the-finals/index.html",
    "title": "How many wins do NRL teams need to make the finals?",
    "section": "",
    "text": "Sounds like a simple problem, but it isn‚Äôt.\nIt‚Äôs pretty common for sports teams to set a goal at the start of a season to make the finals/playoffs . Teams in the NRL1 are no different. The flaw in this goal is that the number of wins needed to qualify for the finals varies from season-to-season depending on the results of other teams. A 12-win season (from 24 games) is enough to qualify some years, but not enough in others.\nSo how many wins do teams need to be confident they‚Äôll qualify?\n\n\nCode\n# Setup\nlibrary(tidyverse)\nlibrary(furrr)\nlibrary(parallel)\nlibrary(igraph)\nlibrary(ggdist)\nlibrary(data.table)\nlibrary(ggtext)\nlibrary(gganimate)\nlibrary(gt)\nlibrary(gtExtras)\n\ncolours &lt;- c(\"#E31937\", \"#134A8E\")\nsocials &lt;- mitchhenderson::social_caption(icon_colour = \"dodgerblue\")\nmitchhenderson::font_hoist(\"Myriad Pro\")\n\ntheme_set(theme_minimal() +\n            theme(text = element_text(family = \"Myriad Pro Regular\"),\n                  plot.caption = element_markdown(),\n                  plot.title = element_markdown(family = \"Myriad Pro Bold Condensed\", \n                                                size = 18),\n                  plot.subtitle = element_markdown(family = \"Myriad Pro Regular\"),\n                  plot.title.position = \"plot\",\n                  panel.grid.minor = element_blank()))\n\n\nTo work it out, I scraped 10 seasons of match result data from Wikipedia (2014-2024 excluding the shortened 2020 season) and saved the results in a file.\n\n# Import match results for 10 seasons (up to 2024)\nimport &lt;- read_csv(\"https://raw.githubusercontent.com/mitchhenderson/mitchhenderson.dev/refs/heads/main/posts/2025-01-18-how-many-wins-do-nrl-teams-need-to-make-the-finals/2014-2024_nrl_match_results.csv\")\n\nThe first 10 rows look like this:\n\n\nCode\nimport |&gt;\n  slice_head(n = 10) |&gt;\n  gt() |&gt;\n  gt_theme_538(quiet = TRUE)\n\n\n\n\n\n  \n    \n      home\n      home_score\n      away_score\n      away\n      day_and_time\n      venue\n      season\n    \n  \n  \n    South Sydney Rabbitohs\n28\n8\nSydney Roosters\n6 March 2014, 8:05 pm\nANZ Stadium, Sydney\n2014\n    Canterbury Bankstown Bulldogs\n12\n18\nBrisbane Broncos\n7 March 2014, 8:05 pm\nANZ Stadium, Sydney\n2014\n    Penrith Panthers\n30\n8\nNewcastle Knights\n8 March 2014, 4:30 pm\nSportingbet Stadium\n2014\n    Manly Warringah Sea Eagles\n22\n23\nMelbourne Storm\n8 March 2014, 7:00 pm\nBrookvale Oval\n2014\n    North Queensland Cowboys\n28\n22\nCanberra Raiders\n8 March 2014, 8:00 pm\n1300SMILES Stadium\n2014\n    St George Illawarra Dragons\n44\n24\nWests Tigers\n9 March 2014, 3:00 pm\nANZ Stadium, Sydney\n2014\n    Parramatta Eels\n36\n16\nNew Zealand Warriors\n9 March 2014, 3:00 pm\nPirtek Stadium\n2014\n    Cronulla Sutherland Sharks\n12\n18\nGold Coast Titans\n10 March 2014, 7:00 pm\nRemondis Stadium\n2014\n    Manly Warringah Sea Eagles\n14\n12\nSouth Sydney Rabbitohs\n14 March 2014, 7:40 pm\nBluetongue Stadium\n2014\n    Brisbane Broncos\n16\n12\nNorth Queensland Cowboys\n14 March 2014, 7:40 pm\nSuncorp Stadium\n2014"
  },
  {
    "objectID": "posts/2025-01-18-how-many-wins-do-nrl-teams-need-to-make-the-finals/index.html#footnotes",
    "href": "posts/2025-01-18-how-many-wins-do-nrl-teams-need-to-make-the-finals/index.html#footnotes",
    "title": "How many wins do NRL teams need to make the finals?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNational Rugby League‚Ü©Ô∏é\nIf anyone knows if / how this can be done, let me know!‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html",
    "href": "posts/2025-01-02-e1rm-modelling/index.html",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "",
    "text": "tl;dr\n\n\n\nYou can get more accurate 1RM estimates by using a statistical model that accounts for differences between athletes. They can also tell you how certain their estimate are (which matters).\nS&C coaches collect training data to monitor progress and evaluate the effectiveness of their programming. A common method in strength training is to calculate an estimated one repetition maximum (or e1RM) using a formula and track how it changes over time. Lots of coaches are happy to use e1RM as a progress indicator instead of testing a true 1RM during a program or in-season because they don‚Äôt negatively impact training (integrates into existing training sessions), are safer (lower weight), and data can be collected more frequently (faster program refinements). True 1RM testing might only be programmed a handful of times per season (if at all) so using training data to regularly estimate strength increases or detect when a program should be adjusted is a good idea."
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#the-problem",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#the-problem",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "The problem",
    "text": "The problem\nThere are lots of different formulas out there to estimate a 1RM.\n\n\n\n\n\n\nCode\nformulas &lt;- list(\n  Epley = function(reps) {\n    100 / (1 + reps / 30)\n  },\n  Brzycki = function(reps) {\n    100 * (37 - reps) / 36\n  },\n  Mayhew = function(reps) {\n    52.2 + 41.9 * exp(-0.055 * reps)\n  },\n  Lombardi = function(reps) {\n    100 / (reps^0.10)\n  },\n  `O'Conner` = function(reps) {\n    100 / (1 + reps / 40)\n  },\n  Wathan = function(reps) {\n    48.8 + 53.8 * exp(-0.075 * reps)\n  },\n  Lander = function(reps) {\n    101.3 - 2.67123 * reps\n  }\n)\n\nreps_range &lt;- 1:20\n\ne1rm_data &lt;- tibble(reps = reps_range) |&gt;\n  crossing(formula = names(formulas)) |&gt;\n  mutate(\n    percent_1rm = map2_dbl(formula, reps, ~ formulas[[.x]](.y))\n  )\n\ne1rm_data_animated &lt;- e1rm_data |&gt;\n  crossing(highlight = unique(e1rm_data$formula)) |&gt;\n  mutate(\n    is_highlighted = formula == highlight,\n    line_color = if_else(is_highlighted, \"highlighted\", \"grey\"),\n    label = if_else(is_highlighted & reps == max(reps), formula, NA_character_),\n    line_size = if_else(is_highlighted, 2, 0.5)\n  )\n\nanimated_plot &lt;- e1rm_data_animated |&gt;\n  ggplot(aes(x = reps, y = percent_1rm, group = formula)) +\n  coord_cartesian(xlim = c(1, 20), clip = \"off\") +\n  geom_line(\n    data = e1rm_data_animated |&gt; filter(!is_highlighted),\n    aes(linewidth = line_size),\n    colour = \"grey70\"\n  ) +\n  geom_line(\n    data = e1rm_data_animated |&gt; filter(is_highlighted),\n    aes(linewidth = line_size),\n    colour = \"#E31937\"\n  ) +\n  geom_text(\n    aes(label = label),\n    colour = \"#E31937\",\n    family = \"Myriad Pro Regular\",\n    hjust = 0,\n    nudge_x = 0.5,\n    size = 6,\n    fontface = \"bold\",\n    show.legend = FALSE\n  ) +\n  scale_linewidth_identity() +\n  scale_x_continuous(\n    breaks = seq(1, 20, 1)\n  ) +\n  scale_y_continuous(\n    labels = label_percent(scale = 1),\n    breaks = seq(40, 100, 10),\n    limits = c(40, 100)\n  ) +\n  labs(\n    title = \"1RM Estimation Formulas\",\n    x = \"Number of Repetitions\",\n    y = NULL,\n    subtitle = \"% of 1RM\",\n    caption = socials\n  ) +\n  theme(\n    plot.margin = margin(10, 100, 10, 10),\n    legend.position = \"none\"\n  ) +\n  transition_manual(\n    highlight,\n    cumulative = FALSE\n  )\n\nanimate(\n  animated_plot,\n   nframes = 80,\n   fps = 10,\n   width = 8,\n   height = 4.5,\n   device = \"ragg_png\"\n)\n\n\n\n\n\n\nCode\nformulas = {\n    \"Epley\": lambda reps: 100 / (1 + reps / 30),\n    \"Brzycki\": lambda reps: 100 * (37 - reps) / 36,\n    \"Mayhew\": lambda reps: 52.2 + 41.9 * np.exp(-0.055 * reps),\n    \"Lombardi\": lambda reps: 100 / (reps**0.10),\n    \"O'Conner\": lambda reps: 100 / (1 + reps / 40),\n    \"Wathan\": lambda reps: 48.8 + 53.8 * np.exp(-0.075 * reps),\n    \"Lander\": lambda reps: 101.3 - 2.67123 * reps,\n}\n\n# Generate data\nreps_range = np.arange(1, 21)\nformula_names = list(formulas.keys())\n\n# Calculate %1RM for each formula\ne1rm_data = {name: func(reps_range) for name, func in formulas.items()}\n\n# Create figure and initial empty lines\nfig, ax = plt.subplots(figsize=(10, 5.5))\nfig.subplots_adjust(right=0.85)\n\n# Store line objects\ngrey_lines = []\nfor name in formula_names:\n    (line,) = ax.plot([], [], color=\"lightgrey\", linewidth=0.8)\n    grey_lines.append(line)\n\n(highlight_line,) = ax.plot([], [], color=\"#E31937\", linewidth=2.5)\nlabel_text = ax.text(\n    20.5, 50, \"\", color=\"#E31937\", fontsize=12, fontweight=\"bold\", va=\"center\"\n)\n\nax.set_xlim(1, 23)\nax.set_ylim(40, 100)\nax.set_xticks(range(1, 21))\nax.set_yticks(range(40, 101, 10))\nax.set_yticklabels([f\"{y}%\" for y in range(40, 101, 10)])\nax.set_xlabel(\"Number of Repetitions\")\nax.set_title(\"1RM Estimation Formulas\", fontweight=\"bold\", fontsize=14)\nax.spines[[\"top\", \"right\"]].set_visible(False)\n\n\ndef init():\n    for line in grey_lines:\n        line.set_data([], [])\n    highlight_line.set_data([], [])\n    label_text.set_text(\"\")\n    return grey_lines + [highlight_line, label_text]\n\n\ndef animate(frame):\n    highlighted = formula_names[frame]\n\n    # Update all lines\n    for i, name in enumerate(formula_names):\n        if name != highlighted:\n            grey_lines[i].set_data(reps_range, e1rm_data[name])\n            grey_lines[i].set_color(\"lightgrey\")\n        else:\n            grey_lines[i].set_data([], [])\n\n    # Update highlighted line\n    highlight_line.set_data(reps_range, e1rm_data[highlighted])\n\n    # Update label\n    label_text.set_position((20.5, e1rm_data[highlighted][-1]))\n    label_text.set_text(highlighted)\n\n    return grey_lines + [highlight_line, label_text]\n\n\nanim = animation.FuncAnimation(\n    fig, animate, init_func=init, frames=len(formula_names), interval=1000, blit=True\n)\n\nanim.save(\"1rm_formulas.gif\", writer=\"pillow\", fps=1)\nplt.close()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBut none of these:\n\nAccount for strength endurance differences between athletes\nSome athletes (fast twitch, higher metabolic cost per rep) have high 1RMs but find higher rep sets challenging. Other athletes (better oxidative capacity, lower metabolic cost per rep) can perform many reps at moderate intensities but quickly hit their 1RM ceiling with more weight. A better 1RM estimate would take into account what‚Äôs known about the physiological characteristics of the athlete. This directly impacts how accurate the e1RM will be. If a fast twitch athlete does a max reps set of 14 x 100kg, I‚Äôd expect their 1RM to be higher than a more oxidative athlete performing the same 14 x 100kg because they‚Äôre better suited to high intensity work.\nThe standard formulas don‚Äôt do this.\n\nTell me how certain they are in their estimate\nThe standard formulas WILL ALWAYS give you a 1RM estimate, doesn‚Äôt matter how confident or UNconfident they are. The 1RM estimate will also always just be a single value. There‚Äôs a big difference in how I‚Äôd interpret a 100kg e1RM if it‚Äôs 80% certain of being between 98‚Äì102kg (pretty precise) versus 80% certain of being between 77.5‚Äì122.5kg (practically useless). There‚Äôs also a big difference in 1RM certainty when the estimate is based on an athlete doing a max rep set completing 2-5 reps (closer to true 1RM; higher certainty) compared 10+ reps (further from true 1RM; lower certainty).\nWe also become more familiar about an athlete‚Äôs ability the more we work with them and get to know them. I‚Äôd have a lot more confidence predicting the 1RM of an athlete I‚Äôd worked with, gotten to know, and collected training data on for years compared to someone new without much training data available. A better 1RM estimate would incorporate all these sources of uncertainty and honestly express how confident it is.\nThe standard formulas don‚Äôt do this."
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#my-solution",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#my-solution",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "My solution",
    "text": "My solution\nThe idea is to extend one of the standard e1RM formulas by building it into a statistical model that takes the athlete it‚Äôs estimating the 1RM for into account. It‚Äôll be fit using the athlete‚Äôs past data so it learns how they handle higher weight vs higher reps. It‚Äôs like a smarter version of the standard formula tailored to the athlete. Having this extra information helps it make more accurate predictions.\nThe model will also be a Bayesian model. These have advantages over conventional statistical models when it comes to expressing uncertainty (among other things). So instead of just getting one number, you get a full distribution representing the uncertainty in the 1RM estimate (e.g., ‚ÄúThe 1RM estimate is 100kg with 80% probability of it being between 98 and 102kg‚Äù).1 This distribution accounts for all the sources of upstream uncertainty (amount of data available on the athlete lifting, number of reps they completed, etc).\nTo show you what I mean, we need some data.\n\nSimulate data\n\n\n\n\n\n\nCode\nset.seed(2534)\n\n# Population hyperparameters (ground truth)\nn_athletes &lt;- 30\nmean_n_obs_per_athlete &lt;- 15\nmin_n_obs &lt;- 5\nmax_n_obs &lt;- 30\n\n# True 1RM population parameters\npop_mean_1rm &lt;- 140\npop_sd_1rm &lt;- 15\n\n# Endurance coefficient population parameters\npop_mean_endurance &lt;- 30\npop_sd_endurance &lt;- 5\n# Maybe discuss importance of this on results (heterogenous endurance profiles = bigger gain from player specific parameters)\n\nmin_reps &lt;- 2\nmax_reps &lt;- 15\n\n# Observation noise\nobs_noise_sd &lt;- 2\n\n# Generate athlete-level ground truth\nathletes &lt;- tibble(\n  athlete_id = 1:n_athletes,\n  true_1rm = rnorm(n_athletes, mean = pop_mean_1rm, sd = pop_sd_1rm),\n  true_endurance = rnorm(\n    n_athletes,\n    mean = pop_mean_endurance,\n    sd = pop_sd_endurance\n  ),\n  n_observations = sample(min_n_obs:max_n_obs, n_athletes, replace = TRUE)\n)\n\n# Generate observations\nsimulated_data &lt;- athletes |&gt;\n  rowwise() |&gt;\n  reframe(\n    athlete_id = athlete_id,\n    true_1rm = true_1rm,\n    true_endurance = true_endurance,\n    session_id = seq_len(n_observations),\n    reps = sample(min_reps:max_reps, n_observations, replace = TRUE)\n  ) |&gt;\n  mutate(\n    # Theoretical weight from modified Epley formula\n    weight_theoretical = true_1rm / (1 + reps / true_endurance),\n\n    # Add normally distributed noise\n    weight_observed = weight_theoretical + rnorm(n(), 0, obs_noise_sd)\n  )\n\n\n\n\n\n\n\n\n\n\nDifferent random number generators\n\n\n\nR and Python use different random number generation algorithms, so even with the same seed value, the simulated data will differ between languages. This means specific values (e.g.¬†individual athlete 1RMs, credible intervals) won‚Äôt match exactly. The overall patterns will be consistent, and the same analytical conclusions apply.\n\n\n\n\nCode\nnp.random.seed(2534)\n\n# Population hyperparameters (ground truth)\nn_athletes = 30\nmean_n_obs_per_athlete = 15\nmin_n_obs = 5\nmax_n_obs = 30\n\n# True 1RM population parameters\npop_mean_1rm = 140\npop_sd_1rm = 15\n\n# Endurance coefficient population parameters\npop_mean_endurance = 30\npop_sd_endurance = 5\n\nmin_reps = 2\nmax_reps = 15\n\n# Observation noise\nobs_noise_sd = 2\n\n# Generate athlete-level ground truth\nathletes = pl.DataFrame(\n    {\n        \"athlete_id\": range(1, n_athletes + 1),\n        \"true_1rm\": np.random.normal(pop_mean_1rm, pop_sd_1rm, n_athletes),\n        \"true_endurance\": np.random.normal(\n            pop_mean_endurance, pop_sd_endurance, n_athletes\n        ),\n        \"n_observations\": np.random.randint(min_n_obs, max_n_obs + 1, n_athletes),\n    }\n)\n\n# Generate observations by expanding each athlete's rows\nn_total = athletes[\"n_observations\"].sum()\n\nsimulated_data = (\n    athletes.select(\n        pl.col(\"athlete_id\").repeat_by(\"n_observations\").explode(),\n        pl.col(\"true_1rm\").repeat_by(\"n_observations\").explode(),\n        pl.col(\"true_endurance\").repeat_by(\"n_observations\").explode(),\n    )\n    .with_columns(\n        session_id=pl.int_range(pl.len()).over(\"athlete_id\") + 1,\n    )\n    .with_columns(\n        reps=pl.Series(np.random.randint(min_reps, max_reps + 1, n_total)),\n    )\n    .with_columns(\n        weight_theoretical=pl.col(\"true_1rm\")\n        / (1 + pl.col(\"reps\") / pl.col(\"true_endurance\")),\n    )\n    .with_columns(\n        weight_observed=pl.col(\"weight_theoretical\")\n        + pl.Series(np.random.normal(0, obs_noise_sd, n_total)),\n    )\n)\n\n\n\n\n\nI‚Äôve simulated 30 fake athletes, each with their own 1RM, strength endurance capacity, and number of previous sessions of data where they‚Äôve performed a max reps set for this given exercise.\n\n\n\n\n\n\nNote\n\n\n\nI‚Äôm going light on simulation details here to keep this accessible. Expand the section below to get more statistical details on the parameters of the simulated data.\n\n\n\nSimulation technical details (optional)\nI‚Äôve defined the ‚Äúsquad‚Äù (30 athletes) to have a mean 1RM of 140kg\nand standard deviation of 15kg drawn from a random normal distribution.\nI also assign them an endurance ability (also drawn\nfrom a normal distribution with a mean of 30 and standard deviation of\n5).\nEach athlete will have data from somewhere between 5 and 30 previous\ntraining sessions where they‚Äôve done this exercises til failure.\nFor each of these max rep sets, the athletes complete somewhere\nbetween 2 and 15 reps (randomly sampled with replacement from a uniform\ndistribution). I calculate a theoretical weight they should be able to\ncomplete for the set given their simulated 1RM and reps performed based\non a modified Epley formula (probably most commonly used e1RM formula,\nmodified to account for variable endurance ability).\nI finally simulate the actual weight they lifted for the set by\ntaking the weight they theoretically could lift given their simulated\n1RM and reps, added some random noise (because humans work like that)\ndrawn randomly from a normal distribution (mean of 0, SD of 2).\n\nThe simulated athlete data looks like this:\n\n\n\n\n\n\nCode\nathletes |&gt;\n  mutate(across(where(is.numeric), \\(x) round(x, 1))) |&gt;\n  gt_preview() |&gt;\n  gt_theme_538(quiet = TRUE)\n\n\n\n\n\n\nCode\npreview_df = pl.concat(\n    [\n        athletes.head(5).with_columns(cs.by_dtype(pl.Float64).round(1)).cast(pl.String),\n        pl.DataFrame({col: [\"‚ãÆ\"] for col in athletes.columns}),\n        athletes.tail(1).with_columns(cs.by_dtype(pl.Float64).round(1)).cast(pl.String),\n    ]\n)\n\nGT(preview_df)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      athlete_id\n      true_1rm\n      true_endurance\n      n_observations\n    \n  \n  \n    1\n1\n145.4\n27.8\n28\n    2\n2\n131.2\n41.8\n20\n    3\n3\n139.6\n31.8\n21\n    4\n4\n133.6\n26.1\n29\n    5\n5\n97.8\n32.9\n30\n    6..29\n\n\n\n\n    30\n30\n147.9\n28.5\n6\n  \n  \n  \n\n\n\n\nI use these athletes and their characteristics to simulate realistic weights and reps. This gives me 582 simulated max rep sets across the 30 athletes.\nThe simulated sets data looks like this:\n\n\n\n\n\n\nCode\nsimulated_data |&gt;\n  select(-starts_with(\"true\"), -weight_theoretical) |&gt;\n  mutate(across(where(is.numeric), \\(x) round(x, 1))) |&gt;\n  gt_preview() |&gt;\n  gt_theme_538(quiet = TRUE)\n\n\n\n\n\n\nCode\nsets_preview = simulated_data.select(\n    pl.exclude(\"^true.*$\", \"weight_theoretical\")\n).with_columns(cs.by_dtype(pl.Float64).round(1))\n\npreview_df = pl.concat(\n    [\n        sets_preview.head(5).cast(pl.String),\n        pl.DataFrame({col: [\"‚ãÆ\"] for col in sets_preview.columns}),\n        sets_preview.tail(1).cast(pl.String),\n    ]\n)\n\nGT(preview_df)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      athlete_id\n      session_id\n      reps\n      weight_observed\n    \n  \n  \n    1\n1\n1\n7\n116.9\n    2\n1\n2\n15\n94.3\n    3\n1\n3\n4\n127.8\n    4\n1\n4\n14\n99.4\n    5\n1\n5\n3\n128.0\n    6..581\n\n\n\n\n    582\n30\n6\n7\n116.2\n  \n  \n  \n\n\n\n\n\n\nThe model\nI‚Äôll specify the model to follow a modified Epley formula.\nReasons for this:\n\nIt‚Äôs probably the most commonly used of the standard 1RM estimate formulas\nIt‚Äôs fairly simple (good for demo purposes)\nI used it as part of how the data was simulated, so seeing how the model‚Äôs performance compares to the standard Epley formula for predicting the true (albeit simulated) 1RMs will be a good test.\n\n\n\n\n\n\n\nNote\n\n\n\nIf I had real training data (instead of simulated), I would fit a bunch of different model specifications to see which one performs best.\n\n\nThe standard Epley is weight * (1 + reps / 30).\nThe modification I‚Äôm using just changes the 30 (fixed constant representing how quickly strength drops off with more reps; same for everyone) to a parameter the model will optimise based on the data for each athlete. Each athlete gets their own value for this based on how they handle high intensity sets or high volume sets.\nI‚Äôll fit the model on all the simulated data except the most recent set for each athlete. I‚Äôll keep these sets as a small holdout or test data for comparing predictive performance between my model and the standard Epley formula.\n\nStats details about the model (optional)\nThe standard Epley formula estimates 1RM from a submaximal lift, but\nthis treats 1RM as the outcome (which we don‚Äôt observe directly). What\nwe actually observe is the weight lifted for a given number of reps.\nSolving for weight, the formula becomes\nweight = 1RM / (1 + reps / 30). This makes weight the\noutcome, matching the data that‚Äôs observed in reality. The 1RM becomes a\nlatent parameter we estimate, and we replace the fixed constant 30 with\nan estimated endurance parameter, which is log-transformed to\nensure positivity and improve sampling efficiency.\nThe hierarchical structure specifies that both 1RM and endurance vary\nby athlete with partial pooling. The amount of regularisation or\nshrinkage is adaptive. Athletes with less data get pulled more toward\nthe group mean and athletes with more data retain more of their\nindividual signal.\nWeakly informative priors regularise the model (preventing\noverfitting and improving convergence) without dominating the\nlikelihood. With reasonable data, the posterior will be driven primarily\nby the observed (simulated) data.\nAlthough they‚Äôre not included in this post (I wanted to keep it\ntight), I did do prior predictive checks (to ensure my priors were\nplausible), model diagnostic checks (to ensure no issues during\nsampling), and posterior predictive checks (to ensure the model‚Äôs\nassumptions adequately captured the features of the observed data).\n\n\n\n\n\n\n\nCode\n# Data prep\nmodel_data &lt;- simulated_data |&gt;\n  rename(\n    # brms doesn't like underscores or . in variable names\n    athlete = athlete_id,\n    orm = true_1rm,\n    weight = weight_observed\n  )\n\n# Train/test split: hold out last observation per athlete\nholdout &lt;- model_data |&gt;\n  group_by(athlete) |&gt;\n  slice_max(session_id, n = 1) |&gt;\n  ungroup()\n\ntrain &lt;- model_data |&gt;\n  anti_join(holdout, by = c(\"athlete\", \"session_id\"))\n\n# Model specification\nmodified_epley_formula &lt;- bf(\n  weight ~ orm / (1 + reps / exp(logk)),\n  orm ~ 1 + (1 | athlete),\n  logk ~ 1 + (1 | athlete),\n  nl = TRUE\n)\n\n# Prior specification\nmodified_epley_priors &lt;- c(\n  prior(normal(140, 30), nlpar = \"orm\", coef = \"Intercept\"),\n  prior(normal(3.4, 0.3), nlpar = \"logk\", coef = \"Intercept\"), # log(30) ‚âà 3.4\n  prior(exponential(0.05), class = \"sd\", nlpar = \"orm\"),\n  prior(exponential(2), class = \"sd\", nlpar = \"logk\"),\n  prior(exponential(0.2), class = \"sigma\")\n)\n\n\nmodified_epley_model_fit &lt;- brm(\n  formula = modified_epley_formula,\n  data = train,\n  prior = modified_epley_priors,\n  family = gaussian(),\n  cores = 4,\n  chains = 4,\n  iter = 4000,\n  warmup = 2000,\n  control = list(adapt_delta = 0.95, max_treedepth = 12),\n  seed = 2534,\n  file = \"modified_epley_model_fit\"\n)\n\nestimate_1rm &lt;- function(model, athlete_id, weight, reps) {\n  model |&gt;\n    spread_draws(b_logk_Intercept, r_athlete__logk[athlete, ]) |&gt;\n    filter(athlete == athlete_id) |&gt;\n    mutate(\n      est_endurance = exp(b_logk_Intercept + r_athlete__logk),\n      est_1RM = weight * (1 + reps / est_endurance)\n    ) |&gt;\n    select(.draw, athlete, est_endurance, est_1RM)\n}\n\n\n\n\n\n\nCode\n# Data prep\nmodel_data = simulated_data.rename(\n    {\"athlete_id\": \"athlete\", \"true_1rm\": \"orm\", \"weight_observed\": \"weight\"}\n)\n\n# Train/test split: hold out last observation per athlete\nholdout = model_data.sort(\"session_id\").group_by(\"athlete\").last()\n\ntrain = model_data.join(\n    holdout.select(\"athlete\", \"session_id\"), on=[\"athlete\", \"session_id\"], how=\"anti\"\n)\n\n# Convert to numpy for PyMC\nathlete_idx, athlete_codes = (\n    train[\"athlete\"].to_numpy(),\n    np.unique(train[\"athlete\"].to_numpy()),\n)\nathlete_idx_mapped = np.array([np.where(athlete_codes == a)[0][0] for a in athlete_idx])\nn_athletes = len(athlete_codes)\nweight = train[\"weight\"].to_numpy()\nreps = train[\"reps\"].to_numpy()\n\n# Model specification\nwith pm.Model() as modified_epley_model:\n    # Hyperpriors\n    orm_mu = pm.Normal(\"orm_mu\", mu=140, sigma=30)\n    orm_sigma = pm.Exponential(\"orm_sigma\", 0.05)\n\n    logk_mu = pm.Normal(\"logk_mu\", mu=3.4, sigma=0.3)  # log(30) ‚âà 3.4\n    logk_sigma = pm.Exponential(\"logk_sigma\", 2)\n\n    # Athlete-level parameters\n    orm_athlete = pm.Normal(\"orm_athlete\", mu=orm_mu, sigma=orm_sigma, shape=n_athletes)\n    logk_athlete = pm.Normal(\n        \"logk_athlete\", mu=logk_mu, sigma=logk_sigma, shape=n_athletes\n    )\n\n    # Observation noise\n    sigma = pm.Exponential(\"sigma\", 0.2)\n\n    # Modified Epley formula: weight = orm / (1 + reps / exp(logk))\n    mu = orm_athlete[athlete_idx_mapped] / (\n        1 + reps / np.exp(logk_athlete[athlete_idx_mapped])\n    )\n\n    # Likelihood\n    weight_obs = pm.Normal(\"weight_obs\", mu=mu, sigma=sigma, observed=weight)\n\n    # Sample\n    modified_epley_trace = pm.sample(\n        draws=2000,\n        tune=2000,\n        cores=4,\n        chains=4,\n        random_seed=2534,\n        target_accept=0.95,\n    )\n\n\n# Function to estimate 1RM\ndef estimate_1rm(trace, athlete_id, weight, reps, n_samples=4000):\n    # Get athlete index\n    athlete_idx = np.where(athlete_codes == athlete_id)[0][0]\n\n    # Extract posterior samples\n    logk_samples = trace.posterior[\"logk_athlete\"].values.reshape(-1, n_athletes)[\n        :, athlete_idx\n    ]\n\n    # Calculate estimated 1RM for each posterior sample\n    est_endurance = np.exp(logk_samples)\n    est_1rm = weight * (1 + reps / est_endurance)\n\n    return {\n        \"athlete\": athlete_id,\n        \"est_endurance\": est_endurance[:n_samples],\n        \"est_1rm\": est_1rm[:n_samples],\n    }\n\n\n\n\n\nNow the model is fit, I use it to make 1RM estimates with the help of a custom function I‚Äôve defined called estimate_1rm(). It takes the model object, the athlete ID, and the weight and reps the athlete performed in the set as arguments and gives me back a distribution of predictions.\n\n\n\n\n\nexample_predictions &lt;- estimate_1rm(\n  model = modified_epley_model_fit,\n  athlete_id = 17,\n  weight = 102.5,\n  reps = 5\n)\n\n\n\n\nexample_predictions = estimate_1rm(\n    trace=modified_epley_trace, athlete_id=17, weight=102.5, reps=5\n)\n\n\n\n\n\n\n\n\n\n\nCode\nexample_dist &lt;- example_predictions |&gt;\n  ggplot(aes(x = est_1RM)) +\n  stat_slab(fill = lighten(colours[2], 0.75)) +\n  stat_spike(at = \"median\", size = 0, colour = colours[2]) +\n  scale_thickness_shared() +\n  annotate(\n    \"curve\",\n    x = 120.5,\n    xend = median(example_predictions$est_1RM) + 0.1,\n    y = 1,\n    yend = 0.925,\n    curvature = 0.25,\n    arrow = arrow(length = unit(2, \"mm\"), type = \"closed\"),\n    colour = \"grey60\"\n  ) +\n  annotate(\n    \"text\",\n    x = 121.3,\n    y = 0.95,\n    label = \"1RM estimate\\n(median)\",\n    hjust = 0.5,\n    colour = \"grey35\",\n    family = \"Myriad Pro Regular\"\n  ) +\n  annotate(\n    \"text\",\n    x = 116.7,\n    y = 0.2,\n    label = \"Lower end of\\nestimates\",\n    hjust = 0.5,\n    colour = \"grey35\",\n    family = \"Myriad Pro Regular\"\n  ) +\n  annotate(\n    \"text\",\n    x = 122,\n    y = 0.2,\n    label = \"Upper end of\\nestimates\",\n    hjust = 0.5,\n    colour = \"grey35\",\n    family = \"Myriad Pro Regular\"\n  ) +\n  labs(\n    x = \"Estimated 1RM\",\n    caption = socials,\n    title = \"Full distribution of 1RM estimates\",\n    subtitle = paste0(\"Athlete 17 | Max reps set of 5 @ 102.5\", units)\n  ) +\n  scale_x_continuous(\n    breaks = seq(116, 122, 1),\n    labels = label_number(suffix = units)\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +\n  theme(\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.line.y = element_blank()\n  )\n\nexample_dist\n\n\n\n\n\n\nCode\nexample_pred_df = pd.DataFrame({\"est_1RM\": example_predictions[\"est_1rm\"]})\n\n(\n    ggplot(example_pred_df, aes(x=\"est_1RM\"))\n    + geom_density(fill=\"#a8c7e6\", alpha=0.8)\n    + geom_vline(\n        xintercept=example_pred_df[\"est_1RM\"].median(), color=\"#134A8E\", size=1\n    )\n    + labs(\n        x=\"Estimated 1RM\",\n        y=None,\n        title=\"Full distribution of 1RM estimates\",\n        subtitle=f\"Athlete 17 | Max reps set of 5 @ 102.5{units}\",\n    )\n    + scale_x_continuous(labels=lambda x: [f\"{v:.0f}{units}\" for v in x])\n    + theme_classic()\n    + theme(\n        axis_text_y=element_blank(),\n        axis_ticks_major_y=element_blank(),\n        axis_line_y=element_blank(),\n        axis_title_y=element_blank(),\n        plot_title=element_text(weight=\"bold\"),\n        plot_subtitle=element_text(color=\"grey\"),\n    )\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes the full distribution is a bit much and you just want a summary (e.g.¬†median with 80% credible intervals).2 Easy.\n\n\n\n\n\n\nCode\nexample_summary &lt;- example_predictions |&gt;\n  median_qi(.width = 0.8) |&gt;\n  select(-contains(\"endurance\"), -.interval) |&gt;\n  mutate(across(where(is.numeric), \\(x) round(x, 1))) |&gt;\n  gt() |&gt;\n  gt_theme_538(quiet = TRUE)\n\nexample_summary\n\n\n\n\n\n\nCode\nmedian_1rm = np.median(example_predictions[\"est_1rm\"])\nlower_1rm = np.percentile(example_predictions[\"est_1rm\"], 10)\nupper_1rm = np.percentile(example_predictions[\"est_1rm\"], 90)\n\nsummary_df = pl.DataFrame(\n    {\n        \"athlete\": [example_predictions[\"athlete\"]],\n        \"est_1RM\": [round(median_1rm, 1)],\n        \"est_1RM_lower\": [round(lower_1rm, 1)],\n        \"est_1RM_upper\": [round(upper_1rm, 1)],\n    }\n)\n\nGT(summary_df)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      athlete\n      est_1RM\n      est_1RM.lower\n      est_1RM.upper\n      .width\n      .point\n    \n  \n  \n    17\n119.3\n118.2\n120.3\n0.8\nmedian"
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#how-accurate-is-it",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#how-accurate-is-it",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "How accurate is it?",
    "text": "How accurate is it?\nBy seeing how close the model got to the true 1RM (defined in the simulation), and doing the same for the standard Epley formula, we can compare their predictive accuracy on new sets.3\n\n\n\n\n\n\nCode\nholdout_predictions &lt;- holdout |&gt;\n  rowwise() |&gt;\n  mutate(\n    model_prediction = estimate_1rm(\n      modified_epley_model_fit,\n      athlete,\n      weight,\n      reps\n    ) |&gt;\n      summarise(prediction = median(est_1RM)) |&gt;\n      pull(prediction),\n    standard_epley_prediction = weight * (1 + reps / 30)\n  ) |&gt;\n  ungroup() |&gt;\n  left_join(\n    athletes |&gt; select(athlete = athlete_id, true_1rm),\n    by = \"athlete\"\n  ) |&gt;\n  mutate(\n    model_error = model_prediction - true_1rm,\n    standard_epley_error = standard_epley_prediction - true_1rm,\n    difference = abs(model_error) - abs(standard_epley_error),\n    most_accurate_method = case_when(\n      abs(difference) &lt;= 1 ~ \"Similar predictions (¬±1)\",\n      difference &lt; 0 ~ paste0(\n        \"Model closer by \",\n        round(abs(difference), 1),\n        units\n      ),\n      difference &gt; 0 ~ paste0(\n        \"Formula closer by \",\n        round(abs(difference), 1),\n        units\n      ),\n    )\n  )\n\ntbl &lt;- holdout_predictions |&gt;\n  select(\n    athlete,\n    weight,\n    reps,\n    `True 1RM` = true_1rm,\n    `Model prediction` = model_prediction,\n    `Formula prediction` = standard_epley_prediction,\n    `Most accurate method` = most_accurate_method\n  ) |&gt;\n  mutate(across(where(is.numeric), \\(x) round(x, 1))) |&gt;\n  gt() |&gt;\n  gt_theme_538(quiet = TRUE) |&gt;\n  cols_align(\n    align = \"right\",\n    columns = `Most accurate method`\n  ) |&gt;\n  tab_style(\n    style = cell_fill(color = \"#DCFCE7\"),\n    locations = cells_body(rows = startsWith(`Most accurate method`, \"Model\"))\n  ) |&gt;\n  tab_style(\n    style = cell_text(\n      color = colours[3],\n      weight = \"bold\"\n    ),\n    locations = cells_body(\n      columns = `Most accurate method`,\n      rows = startsWith(`Most accurate method`, \"Model\")\n    )\n  ) |&gt;\n  tab_style(\n    style = cell_fill(color = \"#DBEAFE\"),\n    locations = cells_body(rows = startsWith(`Most accurate method`, \"Formula\"))\n  ) |&gt;\n  tab_style(\n    style = cell_text(\n      color = \"#2563EB\",\n      weight = \"bold\"\n    ),\n    locations = cells_body(\n      columns = `Most accurate method`,\n      rows = startsWith(`Most accurate method`, \"Formula\")\n    )\n  ) |&gt;\n  tab_source_note(\n    source_note = html(socials)\n  ) |&gt;\n  tab_style(\n    style = cell_text(align = \"right\"),\n    locations = cells_source_notes()\n  ) |&gt;\n  tab_options(\n    source_notes.font.size = 15\n  )\n\ntbl\n\n\n\n\n\n\nCode\nholdout_with_truth = holdout.join(\n    athletes.select(pl.col(\"athlete_id\").alias(\"athlete\"), \"true_1rm\"),\n    on=\"athlete\",\n    how=\"left\",\n)\n\n# Get predictions for each holdout observation\nmodel_predictions = []\nfor row in holdout_with_truth.iter_rows(named=True):\n    pred = estimate_1rm(\n        modified_epley_trace,\n        athlete_id=row[\"athlete\"],\n        weight=row[\"weight\"],\n        reps=row[\"reps\"],\n    )\n    model_predictions.append(np.median(pred[\"est_1rm\"]))\n\n# Calculate standard Epley predictions\nholdout_predictions = (\n    holdout_with_truth.with_columns(\n        pl.Series(\"Model prediction\", model_predictions),\n        (pl.col(\"weight\") * (1 + pl.col(\"reps\") / 30)).alias(\"Formula prediction\"),\n    )\n    .with_columns(\n        (pl.col(\"Model prediction\") - pl.col(\"true_1rm\")).alias(\"model_error\"),\n        (pl.col(\"Formula prediction\") - pl.col(\"true_1rm\")).alias(\n            \"standard_epley_error\"\n        ),\n    )\n    .with_columns(\n        (pl.col(\"model_error\").abs() - pl.col(\"standard_epley_error\").abs()).alias(\n            \"difference\"\n        ),\n    )\n    .with_columns(\n        pl.when(pl.col(\"difference\").abs() &lt;= 1)\n        .then(pl.lit(\"Similar predictions (¬±1)\"))\n        .when(pl.col(\"difference\") &lt; 0)\n        .then(\n            pl.lit(\"Model closer by \")\n            + (pl.col(\"difference\").abs().round(1)).cast(pl.String)\n            + pl.lit(units)\n        )\n        .otherwise(\n            pl.lit(\"Formula closer by \")\n            + (pl.col(\"difference\").abs().round(1)).cast(pl.String)\n            + pl.lit(units)\n        )\n        .alias(\"Most accurate method\")\n    )\n)\n\ndisplay_df = (\n    holdout_predictions.sort(\"athlete\")\n    .select(\n        \"athlete\",\n        \"weight\",\n        \"reps\",\n        pl.col(\"true_1rm\").alias(\"True 1RM\"),\n        \"Model prediction\",\n        \"Formula prediction\",\n        \"Most accurate method\",\n    )\n    .with_columns(cs.by_dtype(pl.Float64).round(1))\n)\n\n(\n    GT(display_df)\n    .tab_style(\n        style=style.fill(color=\"#DCFCE7\"),\n        locations=loc.body(\n            rows=pl.col(\"Most accurate method\").str.starts_with(\"Model\")\n        ),\n    )\n    .tab_style(\n        style=style.text(color=\"#16A34A\", weight=\"bold\"),\n        locations=loc.body(\n            columns=\"Most accurate method\",\n            rows=pl.col(\"Most accurate method\").str.starts_with(\"Model\"),\n        ),\n    )\n    .tab_style(\n        style=style.fill(color=\"#DBEAFE\"),\n        locations=loc.body(\n            rows=pl.col(\"Most accurate method\").str.starts_with(\"Formula\")\n        ),\n    )\n    .tab_style(\n        style=style.text(color=\"#2563EB\", weight=\"bold\"),\n        locations=loc.body(\n            columns=\"Most accurate method\",\n            rows=pl.col(\"Most accurate method\").str.starts_with(\"Formula\"),\n        ),\n    )\n)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      athlete\n      weight\n      reps\n      True 1RM\n      Model prediction\n      Formula prediction\n      Most accurate method\n    \n  \n  \n    1\n97.0\n14\n145.4\n143.4\n142.3\nModel closer by 1.1kg\n    2\n119.4\n4\n131.2\n132.1\n135.4\nModel closer by 3.3kg\n    3\n130.8\n3\n139.6\n142.2\n143.9\nModel closer by 1.7kg\n    4\n90.6\n14\n133.6\n139.3\n132.8\nFormula closer by 4.9kg\n    5\n69.5\n13\n97.8\n97.5\n99.7\nModel closer by 1.6kg\n    6\n85.1\n11\n130.6\n128.7\n116.3\nModel closer by 12.4kg\n    7\n108.4\n11\n139.2\n143.5\n148.1\nModel closer by 4.5kg\n    8\n127.7\n4\n144.3\n144.8\n144.7\nSimilar predictions (¬±1)\n    9\n98.5\n14\n137.5\n140.8\n144.5\nModel closer by 3.7kg\n    10\n129.2\n4\n146.0\n145.6\n146.5\nSimilar predictions (¬±1)\n    11\n101.3\n15\n149.9\n147.9\n152.0\nSimilar predictions (¬±1)\n    12\n132.8\n3\n140.8\n142.9\n146.1\nModel closer by 3.2kg\n    13\n98.2\n10\n130.2\n129.5\n130.9\nSimilar predictions (¬±1)\n    14\n103.3\n7\n132.4\n127.5\n127.4\nSimilar predictions (¬±1)\n    15\n111.2\n11\n164.1\n154.2\n152.0\nModel closer by 2.2kg\n    16\n76.2\n15\n111.8\n113.7\n114.3\nSimilar predictions (¬±1)\n    17\n91.7\n9\n119.9\n118.7\n119.2\nSimilar predictions (¬±1)\n    18\n75.3\n14\n109.3\n110.8\n110.5\nSimilar predictions (¬±1)\n    19\n117.9\n9\n142.9\n145.4\n153.3\nModel closer by 7.9kg\n    20\n127.6\n3\n138.3\n139.8\n140.3\nSimilar predictions (¬±1)\n    21\n138.4\n7\n168.7\n166.3\n170.7\nSimilar predictions (¬±1)\n    22\n82.6\n15\n120.8\n125.5\n123.9\nFormula closer by 1.6kg\n    23\n107.8\n6\n123.1\n127.6\n129.4\nModel closer by 1.8kg\n    24\n95.0\n15\n164.6\n168.5\n142.5\nModel closer by 18.2kg\n    25\n104.7\n15\n148.3\n153.7\n157.1\nModel closer by 3.4kg\n    26\n90.7\n3\n102.3\n100.0\n99.7\nSimilar predictions (¬±1)\n    27\n72.3\n14\n124.6\n122.7\n106.0\nModel closer by 16.7kg\n    28\n93.4\n10\n131.2\n131.6\n124.5\nModel closer by 6.2kg\n    29\n111.5\n6\n137.3\n140.3\n133.7\nSimilar predictions (¬±1)\n    30\n116.2\n7\n147.9\n145.1\n143.3\nModel closer by 1.9kg\n  \n  \n    \n      ÔÇå Mitch Henderson\nÓô± mitchhenderson\nÔÇõ mitchhenderson\n    \n  \n  \n\n\n\n\nMean absolute error for the model was 2.7kg.\nMean absolute error for the regular Epley formula was 5.5kg.\nThe model was therefore 2.8kg more accurate on average in this small simulated sample.4"
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#what-has-the-model-learned-about-the-athletes",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#what-has-the-model-learned-about-the-athletes",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "What has the model learned about the athletes?",
    "text": "What has the model learned about the athletes?\n\n\n\n\n\n\nCode\nathlete_endurance_summary &lt;- modified_epley_model_fit |&gt;\n  spread_draws(b_logk_Intercept, r_athlete__logk[athlete, ]) |&gt;\n  mutate(endurance_parameter = exp(b_logk_Intercept + r_athlete__logk)) |&gt;\n  group_by(athlete) |&gt;\n  summarise(mean_endurance_parameter = mean(endurance_parameter)) |&gt;\n  arrange(mean_endurance_parameter)\n\n# Grab the athletes with the worst, median, and best strength endurance\nselected_athletes &lt;- athlete_endurance_summary |&gt;\n  slice(c(2, 15, 30)) |&gt;\n  pull(athlete)\n\nathlete_labels &lt;- athlete_endurance_summary |&gt;\n  filter(athlete %in% selected_athletes) |&gt;\n  mutate(\n    label = paste0(\n      \"Athlete \",\n      athlete,\n      \" (endurance parameter = \",\n      round(mean_endurance_parameter, 0),\n      \")\"\n    )\n  )\n\nendurance_profiles &lt;- modified_epley_model_fit |&gt;\n  spread_draws(\n    b_orm_Intercept,\n    b_logk_Intercept,\n    r_athlete__orm[athlete, ],\n    r_athlete__logk[athlete, ]\n  ) |&gt;\n  filter(athlete %in% selected_athletes) |&gt;\n  mutate(\n    est_1RM = b_orm_Intercept + r_athlete__orm,\n    endurance_parameter = exp(b_logk_Intercept + r_athlete__logk),\n  ) |&gt;\n  crossing(reps = 1:15) |&gt;\n  mutate(pct_est_1RM = 100 / (1 + reps / endurance_parameter)) |&gt;\n  group_by(athlete, reps) |&gt;\n  median_qi(pct_est_1RM, .width = 0.8) |&gt;\n  left_join(athlete_labels, by = \"athlete\")\n\n\n\n\n\n\nCode\nlogk_athlete = modified_epley_trace.posterior[\"logk_athlete\"].values.reshape(\n    -1, n_athletes\n)\n\n# Calculate mean endurance parameter for each athlete\nmean_endurance = np.exp(logk_athlete.mean(axis=0))\nathlete_endurance_summary = pl.DataFrame(\n    {\n        \"athlete\": athlete_codes,\n        \"mean_endurance_parameter\": mean_endurance,\n    }\n).sort(\"mean_endurance_parameter\")\n\n# Select athletes with worst, median, and best endurance\nselected_athletes = (\n    athlete_endurance_summary.row(1),\n    athlete_endurance_summary.row(14),\n    athlete_endurance_summary.row(29),\n)\nselected_athlete_ids = [row[0] for row in selected_athletes]\n\n# Generate endurance profiles across rep range\nreps_range = np.arange(1, 16)\nprofiles = []\n\nfor athlete_id in selected_athlete_ids:\n    athlete_idx = np.where(athlete_codes == athlete_id)[0][0]\n\n    # Get posterior samples for this athlete (no need to add logk_mu)\n    logk_samples = logk_athlete[:, athlete_idx]\n    endurance_samples = np.exp(logk_samples)\n    mean_endurance_param = endurance_samples.mean()\n\n    for reps in reps_range:\n        pct_1rm_samples = 100 / (1 + reps / endurance_samples)\n        profiles.append(\n            {\n                \"athlete\": athlete_id,\n                \"reps\": reps,\n                \"pct_est_1RM\": np.median(pct_1rm_samples),\n                \"lower\": np.percentile(pct_1rm_samples, 10),\n                \"upper\": np.percentile(pct_1rm_samples, 90),\n                \"endurance_param\": round(mean_endurance_param),\n            }\n        )\n\nendurance_profiles = pd.DataFrame(profiles)\nendurance_profiles[\"label\"] = endurance_profiles.apply(\n    lambda row: f\"Athlete {int(row['athlete'])} (endurance = {int(row['endurance_param'])})\",\n    axis=1,\n)\n\n\n\n\n\nTo demonstrate this point, I‚Äôll just show three athletes: the highest endurance (Athlete 12), the lowest endurance (Athlete 27), and one in the middle (Athlete 16).\nSee how each of their endurance parameters (that the model learned from their past training data) changes their 1RM estimate curve to be tailored to their traits.\n\n\n\n\n\n\nCode\npredicted_curves_plot &lt;- endurance_profiles |&gt;\n  ggplot(\n    aes(x = reps, y = pct_est_1RM, colour = label, fill = label)\n  ) +\n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.15, colour = NA) +\n  geom_textline(\n    aes(label = label),\n    hjust = 0.8,\n    size = 5,\n    family = \"Myriad Pro Regular\"\n  ) +\n  scale_y_continuous(labels = label_percent(scale = 1)) +\n  scale_x_continuous(limits = c(1, 15), breaks = seq(1, 15, 1)) +\n  scale_colour_manual(values = c(colours[3], colours[1], colours[2])) +\n  scale_fill_manual(values = c(colours[3], colours[1], colours[2])) +\n  labs(\n    x = \"Repetitions\",\n    title = \"Athletes with lower endurance fatigue faster\",\n    subtitle = \"% of 1RM\",\n    caption = socials,\n    y = NULL\n  ) +\n  theme(legend.position = \"none\")\n\npredicted_curves_plot\n\n\n\n\n\n\nCode\n(\n    ggplot(\n        endurance_profiles, aes(x=\"reps\", y=\"pct_est_1RM\", colour=\"label\", fill=\"label\")\n    )\n    + geom_ribbon(aes(ymin=\"lower\", ymax=\"upper\"), alpha=0.15, linetype=\"None\")\n    + geom_line(size=1)\n    + scale_y_continuous(labels=lambda x: [f\"{v:.0f}%\" for v in x])\n    + scale_x_continuous(limits=(1, 15), breaks=range(1, 16))\n    + scale_colour_manual(values=[colours[2], colours[0], colours[1]])\n    + scale_fill_manual(values=[colours[2], colours[0], colours[1]])\n    + labs(\n        x=\"Repetitions\",\n        y=None,\n        title=\"Athletes with lower endurance fatigue faster\",\n        subtitle=\"% of 1RM\",\n    )\n    + theme_classic()\n    + theme(\n        legend_position=\"bottom\",\n        legend_title=element_blank(),\n        plot_title=element_text(weight=\"bold\"),\n        plot_subtitle=element_text(color=\"grey\"),\n        axis_title_y=element_blank(),\n    )\n)"
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#how-much-does-having-historical-training-data-help",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#how-much-does-having-historical-training-data-help",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "How much does having historical training data help?",
    "text": "How much does having historical training data help?\nWhen the model has more information to estimate a 1RM, it can typically afford to give a more confident estimate.5 Humans do this instinctively; we‚Äôre skeptical at first but grow confident after observing things repeatedly.\nTo demonstrate, here‚Äôs four athletes‚Äô estimates after hypothetically performing a max reps set of 8 @ 100kg, each with a different amount of historical data used to train the model.\nNotice how the shape of the 1RM estimate distribution becomes taller and thinner or wider and flatter as the amount of historical data changes. These shapes represent the level of certainty in the 1RM estimate and incorporate all sources of performance variability in the training data.\n\n\n\n\n\n\nCode\nathletes_varying_obs &lt;- train |&gt;\n  count(athlete, name = \"n_obs\") |&gt;\n  arrange(n_obs) |&gt;\n  slice(seq(1, 30, by = 9))\n\ndata_varying_obs &lt;- athletes_varying_obs |&gt;\n  mutate(\n    estimate = map(\n      athlete,\n      \\(x) estimate_1rm(modified_epley_model_fit, x, 100, 8)\n    ),\n    athlete = factor(\n      athlete,\n      levels = rev(athletes_varying_obs$athlete),\n      labels = paste0(\n        \"Athlete \",\n        rev(athletes_varying_obs$athlete),\n        \"&lt;br&gt;&lt;span style='color:grey50; font-size:11pt;'&gt;(\",\n        rev(n_obs),\n        \" sets of historical data)&lt;/span&gt;\"\n      )\n    )\n  ) |&gt;\n  rename(athlete_id = athlete) |&gt;\n  unnest(estimate)\n\nannotations &lt;- tibble(\n  athlete_id = c(\n    data_varying_obs |&gt;\n      filter(n_obs == max(n_obs)) |&gt;\n      pull(athlete_id) |&gt;\n      unique(),\n    data_varying_obs |&gt;\n      filter(n_obs == min(n_obs)) |&gt;\n      pull(athlete_id) |&gt;\n      unique()\n  ),\n  x = c(130.5, 130.5),\n  y = c(0.4, 0.4),\n  label = c(\n    paste0(\n      \"More data ‚Üí narrower distribution&lt;br&gt;\",\n      max(data_varying_obs$n_obs),\n      \" sets gives high confidence\"\n    ),\n    paste0(\n      \"Less data ‚Üí wider distribution&lt;br&gt;Only \",\n      min(data_varying_obs$n_obs),\n      \" sets means more uncertainty\"\n    )\n  )\n)\n\nhistorical_data_plot &lt;- data_varying_obs |&gt;\n  ggplot(aes(x = est_1RM)) +\n  facet_wrap(~athlete_id, ncol = 1) +\n  stat_slab(fill = lighten(colours[2], 0.75)) +\n  stat_spike(at = \"median\", size = 0, colour = colours[2]) +\n  scale_thickness_shared() +\n  geom_hline(yintercept = 0, colour = \"grey50\", linewidth = 1) +\n  geom_richtext(\n    data = annotations,\n    aes(x = x, y = y, label = label),\n    fill = NA,\n    colour = \"grey35\",\n    hjust = 0.5,\n    label.color = NA,\n    size = 4,\n    family = \"Myriad Pro Regular\"\n  ) +\n  scale_x_continuous(\n    labels = label_number(suffix = units),\n    limits = c(117, 133)\n  ) +\n  labs(\n    y = NULL,\n    x = \"Estimated 1RM\",\n    title = \"1RM estimates with more data are usually more confident\",\n    caption = socials\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +\n  theme(\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.line = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_markdown(family = \"Myriad Pro Regular\", hjust = 0)\n  )\n\nhistorical_data_plot\n\n\n\n\n\n\nCode\nathletes_varying_obs = (\n    train.group_by(\"athlete\")\n    .len()\n    .rename({\"len\": \"n_obs\"})\n    .sort(\"n_obs\")\n    .gather_every(9, offset=0)\n)\n\n# Generate 1RM estimates for each athlete (hypothetical 8 reps @ 100kg)\nvarying_obs_data = []\n\nfor row in athletes_varying_obs.iter_rows(named=True):\n    athlete_id = row[\"athlete\"]\n    n_obs = row[\"n_obs\"]\n\n    pred = estimate_1rm(modified_epley_trace, athlete_id, weight=100, reps=8)\n\n    for est in pred[\"est_1rm\"]:\n        varying_obs_data.append(\n            {\n                \"athlete\": athlete_id,\n                \"n_obs\": n_obs,\n                \"est_1RM\": est,\n            }\n        )\n\nvarying_obs_df = pd.DataFrame(varying_obs_data)\nvarying_obs_df[\"label\"] = varying_obs_df.apply(\n    lambda row: f\"Athlete {int(row['athlete'])} ({int(row['n_obs'])} sets of historical data)\",\n    axis=1,\n)\n\n# Order by n_obs descending for facets\nlabel_order = (\n    varying_obs_df.groupby(\"label\", observed=True)[\"n_obs\"]\n    .first()\n    .sort_values(ascending=False)\n    .index.tolist()\n)\nvarying_obs_df[\"label\"] = pd.Categorical(\n    varying_obs_df[\"label\"], categories=label_order, ordered=True\n)\n\n(\n    ggplot(varying_obs_df, aes(x=\"est_1RM\"))\n    + geom_density(fill=\"#a8c7e6\", alpha=0.8)\n    + geom_vline(\n        varying_obs_df.groupby(\"label\", observed=True)[\"est_1RM\"]\n        .median()\n        .reset_index(),\n        aes(xintercept=\"est_1RM\"),\n        colour=\"#134A8E\",\n        size=0.8,\n    )\n    + facet_wrap(\"~label\", ncol=1)\n    + scale_x_continuous(labels=lambda x: [f\"{v:.0f}{units}\" for v in x])\n    + labs(\n        x=\"Estimated 1RM\",\n        y=\"\",\n        title=\"1RM estimates with more data are usually more confident\",\n    )\n    + theme_classic()\n    + theme(\n        axis_text_y=element_blank(),\n        axis_ticks_major_y=element_blank(),\n        axis_title_y=element_blank(),\n        axis_line_y=element_blank(),\n        strip_text=element_text(ha=\"left\"),\n        strip_background=element_blank(),\n        plot_title=element_text(weight=\"bold\"),\n    )\n)"
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#how-much-1rm-accuracy-do-you-lose-with-higher-rep-sets",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#how-much-1rm-accuracy-do-you-lose-with-higher-rep-sets",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "How much 1RM accuracy do you lose with higher rep sets?",
    "text": "How much 1RM accuracy do you lose with higher rep sets?\nThe further a max reps set is from a true 1RM, the more the model has to extrapolate to provide an estimate. This extrapolation causes uncertainty in the 1RM estimates to compound. I think this is intuitive to most people; predicting the weather a few hours from now isn‚Äôt super hard, but forecasting days or weeks in advance carries a lot more uncertainty because there‚Äôs so much more time for conditions to diverge from your model. Same idea here. Heavy sets where only 2‚Äì5 reps are completed provide more representative evidence of what your 1RM actually is.\n\n\nCode\nset.seed(2534)\n\nrep_count_plot_athlete &lt;- 6\n\nrep_count_plot_athlete_data &lt;- train |&gt;\n  filter(athlete == rep_count_plot_athlete) |&gt;\n  mutate(\n    rep_bin = case_when(\n      reps &lt;= 5 ~ \"low\",\n      reps &lt;= 10 ~ \"mid\",\n      TRUE ~ \"high\"\n    )\n  ) |&gt;\n  group_by(rep_bin) |&gt;\n  slice_sample(n = 1) |&gt;\n  ungroup()\n\nrep_count_plot_athlete_1RM &lt;- rep_count_plot_athlete_data$orm[1]\n\nrep_count_plot_data &lt;- rep_count_plot_athlete_data |&gt;\n  pmap_dfr(\\(reps, weight, ...) {\n    estimate_1rm(\n      modified_epley_model_fit,\n      athlete_id = rep_count_plot_athlete,\n      weight = weight,\n      reps = reps\n    ) |&gt;\n      mutate(scenario = paste0(reps, \" reps @ \", round(weight, 0), units))\n  }) |&gt;\n  mutate(scenario = fct_reorder(scenario, parse_number(scenario)))\n\nscenario_levels &lt;- levels(factor(rep_count_plot_data$scenario))\n\nrep_count_plot_annotations &lt;- tibble(\n  scenario = factor(scenario_levels, levels = scenario_levels),\n  x = rep_count_plot_athlete_1RM - 0.1,\n  y = 1,\n  true_1RM_label = c(\"True 1RM\", NA, NA),\n  annotation = c(\n    \"3 rep set ‚Üí more confident\",\n    NA,\n    \"13 rep set ‚Üí less confident\"\n  )\n)\n\nrep_count_plot_data |&gt;\n  ggplot(aes(x = est_1RM)) +\n  facet_wrap(~scenario, ncol = 1) +\n  stat_slab(fill = lighten(colours[2], 0.75)) +\n  stat_spike(at = \"median\", size = 0, colour = colours[2]) +\n  scale_thickness_shared() +\n  geom_hline(yintercept = 0, colour = \"grey50\", linewidth = 1) +\n  geom_vline(\n    xintercept = rep_count_plot_athlete_1RM,\n    colour = colours[1],\n    linetype = \"dashed\",\n    linewidth = 0.5\n  ) +\n  geom_richtext(\n    data = rep_count_plot_annotations,\n    aes(x = x, y = y, label = true_1RM_label),\n    fill = NA,\n    colour = colours[1],\n    label.color = NA,\n    hjust = 1,\n    family = \"Myriad Pro Regular\"\n  ) +\n  geom_richtext(\n    data = rep_count_plot_annotations,\n    aes(x = x + 4.5, y = 0.4, label = annotation),\n    fill = NA,\n    size = 4.5,\n    colour = \"grey35\",\n    label.color = NA,\n    family = \"Myriad Pro Regular\"\n  ) +\n  labs(\n    x = \"Estimated 1RM (kg)\",\n    y = NULL,\n    title = \"1RM estimates are more confident with lower rep sets\",\n    subtitle = paste0(\n      \"Athlete \",\n      rep_count_plot_athlete,\n      \" | Max rep sets from simulated training data\"\n    ),\n    caption = socials\n  ) +\n  scale_x_continuous(\n    labels = label_number(suffix = units),\n    limits = c(122, 137)\n  ) +\n  theme(\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.line = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_markdown(family = \"Myriad Pro Regular\", hjust = 0)\n  )"
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#integrating-this",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#integrating-this",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "Integrating this",
    "text": "Integrating this\nIntegrating this into a larger system would involve deploying the model to a server so that estimates can be requested on demand. Analysis tools (R, Python, Excel via Power Query, etc) would send athlete data to the model and receive 1RM estimates in return. From there, you‚Äôd set up the model to refit on a schedule so that estimates stay current and are available whenever you‚Äôre programming or reviewing training."
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#conclusion",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#conclusion",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "Conclusion",
    "text": "Conclusion\nMy simulated data might not align with the patterns in real training data, but I think the idea that some athletes can do heavy weight well while others do higher reps well is valid and should/can be captured when you‚Äôre estimating 1RM from a submaximal set for max reps.\nKey takeaways:\n\nAthletes have different characteristics that statistical models can learn and account for when making inferences or predictions.\nQuantifying uncertainty helps us make better decisions. Especially knowing when we don‚Äôt have enough information to act confidently.\nModels like this can be fit to your athletes‚Äô data, updated automatically as new training results come in, and integrated into your programming or monitoring workflows."
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#footnotes",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#footnotes",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that this is different, and IMO much more intuitive, to what a confidence interval tells you. Confidence intervals are confusing and even trained scientists often misinterpret them.‚Ü©Ô∏é\nThese intervals are what you get with Bayesian model estimates and they are what I think most people want confidence intervals to be. There is x% probability that the interval contains the true value.‚Ü©Ô∏é\nThis evaluation is pretty crude (holding out each athletes most recent set for testing; only 30 sets total). It‚Äôs kind of how it would work in real life though; predictions after each new session are like their own test set (assuming model is updated before each session). A stronger approach to evaluation during the research phase of something like (as opposed to ongoing use) would be to use something like cross validation.‚Ü©Ô∏é\nTake with a big grain of salt as it‚Äôs only an average over 30 estimates.‚Ü©Ô∏é\nAlthough more data doesn‚Äôt always mean a more certain estimate, sometimes it‚Äôs just more certain that the athlete is inherently variable.‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2025-01-02-e1rm-modelling/index.html#how-much-accuracy-do-you-lose-with-higher-rep-sets",
    "href": "posts/2025-01-02-e1rm-modelling/index.html#how-much-accuracy-do-you-lose-with-higher-rep-sets",
    "title": "Making 1 rep max estimates more accurate and honest",
    "section": "How much accuracy do you lose with higher rep sets?",
    "text": "How much accuracy do you lose with higher rep sets?\nThe further a max reps set is from a true 1RM, the more the model has to extrapolate to provide an estimate. This extrapolation causes uncertainty in the 1RM estimates to compound. This is intuitive; predicting the weather a few hours from now isn‚Äôt impressive, but forecasting days or weeks in advance is much harder and carries a lot more uncertainty because of the added time for conditions to stray from your expectations.\nSame idea here. Heavy sets where only 2‚Äì5 reps are completed are more representative of what your 1RM actually is.\n\n\n\n\n\n\nCode\nset.seed(2534)\n\nrep_count_plot_athlete &lt;- 6\n\nrep_count_plot_athlete_data &lt;- train |&gt;\n  filter(athlete == rep_count_plot_athlete) |&gt;\n  mutate(\n    rep_bin = case_when(\n      reps &lt;= 5 ~ \"low\",\n      reps &lt;= 10 ~ \"mid\",\n      TRUE ~ \"high\"\n    )\n  ) |&gt;\n  group_by(rep_bin) |&gt;\n  slice_sample(n = 1) |&gt;\n  ungroup()\n\nrep_count_plot_athlete_1RM &lt;- rep_count_plot_athlete_data$orm[1]\n\nrep_count_plot_data &lt;- rep_count_plot_athlete_data |&gt;\n  pmap_dfr(\\(reps, weight, ...) {\n    estimate_1rm(\n      modified_epley_model_fit,\n      athlete_id = rep_count_plot_athlete,\n      weight = weight,\n      reps = reps\n    ) |&gt;\n      mutate(scenario = paste0(reps, \" reps @ \", round(weight, 0), units))\n  }) |&gt;\n  mutate(scenario = fct_reorder(scenario, parse_number(scenario)))\n\nscenario_levels &lt;- levels(factor(rep_count_plot_data$scenario))\n\nrep_count_plot_annotations &lt;- tibble(\n  scenario = factor(scenario_levels, levels = scenario_levels),\n  x = rep_count_plot_athlete_1RM - 0.1,\n  y = 1,\n  true_1RM_label = c(\"True 1RM\", NA, NA),\n  annotation = c(\n    \"3 rep set ‚Üí more confident\",\n    NA,\n    \"13 rep set ‚Üí less confident\"\n  )\n)\n\nrep_count_plot &lt;- rep_count_plot_data |&gt;\n  ggplot(aes(x = est_1RM)) +\n  facet_wrap(~scenario, ncol = 1) +\n  stat_slab(fill = lighten(colours[2], 0.75)) +\n  stat_spike(at = \"median\", size = 0, colour = colours[2]) +\n  scale_thickness_shared() +\n  geom_hline(yintercept = 0, colour = \"grey50\", linewidth = 1) +\n  geom_vline(\n    xintercept = rep_count_plot_athlete_1RM,\n    colour = colours[1],\n    linetype = \"dashed\",\n    linewidth = 0.5\n  ) +\n  geom_richtext(\n    data = rep_count_plot_annotations,\n    aes(x = x, y = y, label = true_1RM_label),\n    fill = NA,\n    colour = colours[1],\n    label.color = NA,\n    hjust = 1,\n    family = \"Myriad Pro Regular\"\n  ) +\n  geom_richtext(\n    data = rep_count_plot_annotations,\n    aes(x = x + 4.5, y = 0.4, label = annotation),\n    fill = NA,\n    size = 4.5,\n    colour = \"grey35\",\n    label.color = NA,\n    family = \"Myriad Pro Regular\"\n  ) +\n  labs(\n    x = \"Estimated 1RM (kg)\",\n    y = NULL,\n    title = \"1RM estimates are more confident with lower rep sets\",\n    subtitle = paste0(\n      \"Athlete \",\n      rep_count_plot_athlete,\n      \" | Max rep sets from simulated training data\"\n    ),\n    caption = socials\n  ) +\n  scale_x_continuous(\n    labels = label_number(suffix = units),\n    limits = c(122, 137)\n  ) +\n  theme(\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.line = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_markdown(family = \"Myriad Pro Regular\", hjust = 0)\n  )\n\nrep_count_plot\n\n\n\n\n\n\nCode\nnp.random.seed(2534)\n\n# Pick an athlete\nrep_count_plot_athlete = 6\n\n# Get their data and sample one set from each rep bin\nrep_count_athlete_data = (\n    train.filter(pl.col(\"athlete\") == rep_count_plot_athlete)\n    .with_columns(\n        pl.when(pl.col(\"reps\") &lt;= 5)\n        .then(pl.lit(\"low\"))\n        .when(pl.col(\"reps\") &lt;= 10)\n        .then(pl.lit(\"mid\"))\n        .otherwise(pl.lit(\"high\"))\n        .alias(\"rep_bin\")\n    )\n    .group_by(\"rep_bin\")\n    .agg(pl.all().sample(n=1, seed=2534))\n    .explode(pl.exclude(\"rep_bin\"))\n)\n\n# Generate predictions for each set\nrep_count_data = []\n\nfor row in rep_count_athlete_data.iter_rows(named=True):\n    pred = estimate_1rm(\n        modified_epley_trace,\n        athlete_id=rep_count_plot_athlete,\n        weight=row[\"weight\"],\n        reps=row[\"reps\"],\n    )\n    scenario = f\"{row['reps']} reps @ {round(row['weight'])}{units}\"\n\n    for est in pred[\"est_1rm\"]:\n        rep_count_data.append(\n            {\n                \"reps\": row[\"reps\"],\n                \"scenario\": scenario,\n                \"est_1RM\": est,\n            }\n        )\n\nrep_count_df = pd.DataFrame(rep_count_data)\n\n# Order scenarios by rep count\nscenario_order = (\n    rep_count_df.groupby(\"scenario\", observed=True)[\"reps\"]\n    .first()\n    .sort_values()\n    .index.tolist()\n)\nrep_count_df[\"scenario\"] = pd.Categorical(\n    rep_count_df[\"scenario\"], categories=scenario_order, ordered=True\n)\n\n(\n    ggplot(rep_count_df, aes(x=\"est_1RM\"))\n    + geom_density(fill=\"#a8c7e6\", alpha=0.8)\n    + geom_vline(\n        rep_count_df.groupby(\"scenario\", observed=True)[\"est_1RM\"]\n        .median()\n        .reset_index(),\n        aes(xintercept=\"est_1RM\"),\n        colour=\"#134A8E\",\n        size=0.8,\n    )\n    + facet_wrap(\"~scenario\", ncol=1)\n    + scale_x_continuous(labels=lambda x: [f\"{v:.0f}{units}\" for v in x])\n    + labs(\n        x=\"Estimated 1RM\",\n        y=\"\",\n        title=\"1RM estimates are more confident with lower rep sets\",\n        subtitle=f\"Athlete {rep_count_plot_athlete} | Max rep sets from simulated training data\",\n    )\n    + theme_classic()\n    + theme(\n        axis_text_y=element_blank(),\n        axis_ticks_major_y=element_blank(),\n        axis_title_y=element_blank(),\n        axis_line_y=element_blank(),\n        strip_text=element_text(ha=\"left\"),\n        strip_background=element_blank(),\n        plot_title=element_text(weight=\"bold\"),\n        plot_subtitle=element_text(color=\"grey\"),\n    )\n)"
  }
]