---
title: "Making 1 rep max estimates more accurate and honest"
description: |
  Use more of the information you have.
author: Mitch Henderson
date: 2025-12-09
thumbnailImage: /img/nrl_finals_probs.png
draft: true
format:
  html:
    code-fold: true
    code-tools: true
    html-table-processing: none
knitr:
    opts_chunk:
      dev: "ragg_png"
---

### **tl;dr**: You can get more accurate 1RM estimates by using a statistical model that accounts for differences between athletes. They can also tell you how certain they are in their estimate (which matters).

<br>

[S&C coaches](https://en.wikipedia.org/wiki/Strength_and_conditioning_coach) collect training data to monitor progress and evaluate the effectiveness of their programming. A common method in strength training is to calculate an [**estimated one repetition maximum**](https://en.wikipedia.org/wiki/One-repetition_maximum#Estimating_1RM) (or e1RM) using a formula and track how it changes over time. Lots of coaches are happy to use e1RM as a progress indicator instead of testing a true 1RM during a program or in-season because they don't impact training (integrates into existing training sessions), are safer (lower weight), and data can be collected more frequently (faster program refinements). [True 1RM](https://en.wikipedia.org/wiki/One-repetition_maximum#Measuring_1RM) testing might only be programmed a handful of times per season (if at all) so using training data to regularly estimate strength increases or detect when a program should be adjusted is a good idea.

```{r}
#| output: false

library(tidyverse)
library(gganimate)
library(scales)
library(ggtext)
library(gt)
library(gtExtras)
library(sn) # skewed normal distribution function
library(tidybayes)
library(ggdist)

mitchhenderson::font_hoist("Myriad Pro")
socials <- mitchhenderson::social_caption(icon_colour = "dodgerblue")

colours <- c("#E31937", "#134A8E")

# theme_set
```

## The problem

There are [lots of different formulas out there to estimate a 1RM](https://maxcalculator.com/guides/1rm-formulas).

```{r}
#| warning: false

# Define the 1RM estimation formulas
# Each formula calculates %1RM based on number of reps
formulas <- list(
  Epley = function(reps) {
    # Epley: 1RM = weight × (1 + reps/30)
    # Therefore: %1RM = 100 / (1 + reps/30)
    100 / (1 + reps / 30)
  },

  Brzycki = function(reps) {
    # Brzycki: 1RM = weight × (36/(37 - reps))
    # Therefore: %1RM = 100 × (37 - reps) / 36
    100 * (37 - reps) / 36
  },

  Mayhew = function(reps) {
    # Mayhew: 1RM = (100 × weight) / (52.2 + 41.9 × exp(-0.055 × reps))
    # Therefore: %1RM = 52.2 + 41.9 × exp(-0.055 × reps)
    52.2 + 41.9 * exp(-0.055 * reps)
  },

  Lombardi = function(reps) {
    # Lombardi: 1RM = weight × reps^0.10
    # Therefore: %1RM = 100 / reps^0.10
    100 / (reps^0.10)
  },

  `O'Conner` = function(reps) {
    # O'Conner: 1RM = weight × (1 + reps/40)
    # Therefore: %1RM = 100 / (1 + reps/40)
    100 / (1 + reps / 40)
  },

  Wathan = function(reps) {
    # Wathan: 1RM = (100 × weight) / (48.8 + 53.8 × exp(-0.075 × reps))
    # Therefore: %1RM = 48.8 + 53.8 × exp(-0.075 × reps)
    48.8 + 53.8 * exp(-0.075 * reps)
  },

  Lander = function(reps) {
    # Lander: 1RM = (100 × weight) / (101.3 - 2.67123 × reps)
    # Therefore: %1RM = 101.3 - 2.67123 × reps
    101.3 - 2.67123 * reps
  }
)

# Generate data for reps 1 to 20
reps_range <- 1:20

# Create a tidy dataframe with all formulas
e1rm_data <- tibble(reps = reps_range) |>
  crossing(formula = names(formulas)) |>
  mutate(
    percent_1rm = map2_dbl(formula, reps, ~ formulas[[.x]](.y))
  )

e1rm_data_animated <- e1rm_data |>
  crossing(highlight = unique(e1rm_data$formula)) |>
  mutate(
    is_highlighted = formula == highlight,
    line_color = if_else(is_highlighted, "highlighted", "grey"),
    label = if_else(is_highlighted & reps == max(reps), formula, NA_character_),
    line_size = if_else(is_highlighted, 2, 0.5)
  )

animated_plot <- e1rm_data_animated |>
  ggplot(aes(x = reps, y = percent_1rm, group = formula)) +
  coord_cartesian(xlim = c(1, 20), clip = "off") +
  geom_line(
    data = e1rm_data_animated |> filter(!is_highlighted),
    aes(linewidth = line_size),
    colour = "grey70"
  ) +
  geom_line(
    data = e1rm_data_animated |> filter(is_highlighted),
    aes(linewidth = line_size),
    colour = "#E31937"
  ) +
  geom_text(
    aes(label = label),
    colour = "#E31937",
    family = "Myriad Pro Regular",
    hjust = 0,
    nudge_x = 0.5,
    size = 6,
    fontface = "bold",
    show.legend = FALSE
  ) +
  scale_linewidth_identity() +
  scale_x_continuous(
    breaks = seq(1, 20, 1)
  ) +
  scale_y_continuous(
    labels = label_percent(scale = 1),
    breaks = seq(40, 100, 10),
    limits = c(40, 100)
  ) +
  labs(
    title = "1RM Estimation Formulas",
    x = "Number of Repetitions",
    y = NULL,
    subtitle = "% of 1RM",
    caption = socials
  ) +
  theme_classic(base_size = 16, base_family = "Myriad Pro Regular") +
  theme(
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(size = 14, color = "grey40", face = "bold"),
    axis.title.x = element_text(size = 14, color = "grey40", face = "bold"),
    panel.grid = element_blank(),
    plot.margin = margin(10, 100, 10, 10),
    plot.caption = element_markdown(color = "grey50", size = 10),
    legend.position = "none",
    axis.ticks = element_blank(),
    axis.line = element_line(colour = "grey50"),
    plot.title.position = "plot"
  ) +
  transition_manual(
    highlight,
    cumulative = FALSE
  )

# Render the animation
animate(
  animated_plot,
  nframes = 80,
  fps = 10,
  width = 8,
  height = 4.5,
  device = "ragg_png"
)
```

But none of these:

-   Account for strength endurance differences between athletes

    Some athletes (fast twitch, higher metabolic cost per rep) have high 1RMs but find higher rep sets challenging. Other athletes (better oxidative capacity, lower metabolic cost per rep) can perform many reps at moderate intensities but quickly hit their 1RM ceiling with more weight. **I want my 1RM estimate to take into account what I know about the physiological characteristics of the athlete**. This directly impacts how accurate the e1RM will be. If a fast twitch athlete does a max reps set of 14 x 100kg, I expect their 1RM to be higher than a more oxidative athlete performing the same 14 x 100kg because I know they are better suited to high intensity work.

    *The standard formulas don't do this*.

-   Tell me how certain they are in their estimate

    The standard formulas WILL ALWAYS give you a 1RM estimate, doesn't matter how *UN*confident they are. The 1RM estimate will also always just be a single value. There's a big difference in how I'd interpret a 100kg e1RM if it's 80% certain of being between 98–102kg (pretty precise) versus 80% certain of being between 77.5–122.5kg (practically useless). There's also a big difference in 1RM certainty when the estimate is based on an athlete doing a max set of 2-5 reps (closer to true 1RM; higher certainty) compared 10+ reps (further from true 1RM; lower certainty). We also become more familiar about an athlete's ability the more we work with them and get to know them. I have a lot more confidence predicting the 1RM of an athlete I've worked with, gotten to know, and collected training data on for years compared to someone new with little training data available. **I want to incorporate all these sources of uncertainty into my 1RM estimate make the most informed decision**.

    *The standard formulas don't do this*.

## My solution

The idea is to extend one of the standard e1RM formulas by building it into a statistical model that takes into account which athlete it's estimating the 1RM for. It'll be trained on the athlete's past data so it learns how they handle higher weight vs higher reps. It's like a smarter version of the standard formula tailored to the athlete. Having this extra information helps it can make more accurate predictions.

The model will also be a [*Bayesian*](https://en.wikipedia.org/wiki/Bayesian_statistics) model. These have advantages over [conventional](https://en.wikipedia.org/wiki/Frequentist_probability) statistical models when it comes to expressing uncertainty ([among other things](https://www.youtube.com/watch?v=R6d-AbkhBQ8)). So instead of just getting a number, you get a full distribution representing the uncertainty in the 1RM estimate (e.g., "The 1RM estimate is 100 with 80% probability of it being between 98 and 102").[^1] This distribution accounts for all the sources of upstream uncertainty (amount of data available on the athlete lifting, number of reps they completed, etc).

[^1]: Note that this is different, and IMO much more intuitive, to what a confidence interval tells you. Confidence intervals are confusing [and even trained scientists often misinterpret them](https://pubmed.ncbi.nlm.nih.gov/24420726/).

To show you what I mean, we need some data.

### Simulate data

```{r}
set.seed(2534)

# Population hyperparameters (ground truth)
n_athletes <- 30
mean_n_obs_per_athlete <- 15
min_n_obs <- 5
max_n_obs <- 30

# True 1RM population parameters
pop_mean_1rm <- 140
pop_sd_1rm <- 15

# Endurance coefficient population parameters
pop_mean_endurance <- 30
pop_sd_endurance <- 3

# Observation noise
obs_noise_sd <- 2.5

# Skewness for observed weights (negative = left skew)
skew_alpha <- -2

# Generate athlete-level ground truth
athletes <- tibble(
  athlete_id = 1:n_athletes,
  true_1rm = rnorm(n_athletes, mean = pop_mean_1rm, sd = pop_sd_1rm),
  true_endurance = rnorm(
    n_athletes,
    mean = pop_mean_endurance,
    sd = pop_sd_endurance
  ),
  n_observations = sample(min_n_obs:max_n_obs, n_athletes, replace = TRUE)
)

# Generate observations
sim_data <- athletes |>
  rowwise() |>
  reframe(
    athlete_id = athlete_id,
    true_1rm = true_1rm,
    true_endurance = true_endurance,
    session_id = seq_len(n_observations),
    reps = sample(2:15, n_observations, replace = TRUE)
  ) |>
  mutate(
    # Theoretical weight from modified Epley formula
    weight_theoretical = true_1rm / (1 + reps / true_endurance),

    # Left-skewed noise using skew-normal distribution
    weight_observed = weight_theoretical +
      rsn(n(), xi = 0, omega = obs_noise_sd, alpha = skew_alpha),

    # Round to realistic real world weight increment (nearest 2.5)
    weight_observed = round(weight_observed / 2.5) * 2.5
  )
```

I've simulated 30 fake athletes, each with their own 1RM, strength endurance capacity, and number of previous sessions of data where they've performed a max reps set for this given exercise.

::: callout-important
I'm glossing over a lot of detail in the simulation here to keep this accessible.
:::

10 picked at random look like this:

```{r}
athletes |>
  slice_sample(n = 10) |>
  mutate(across(where(is.numeric), \(x) round(x, 1))) |>
  gt() |>
  gt_theme_538(quiet = TRUE)
```

I use these athletes and their characteristics to simulate weight and reps for these max rep sets. This gives me `r nrow(sim_data)` simulated max rep sets across the 30 athletes. 10 picked at random look like this:

```{r}
sim_data |>
  select(-starts_with("true"), -weight_theoretical) |>
  slice_sample(n = 10) |>
  mutate(across(where(is.numeric), \(x) round(x, 1))) |>
  gt() |>
  gt_theme_538(quiet = TRUE)
```

### Define model
